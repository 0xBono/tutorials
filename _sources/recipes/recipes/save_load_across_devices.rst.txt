.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_recipes_recipes_save_load_across_devices.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_recipes_recipes_save_load_across_devices.py:


Saving and loading models across devices in PyTorch
===================================================

There may be instances where you want to save and load your neural
networks across different devices.

Introduction
------------

Saving and loading models across devices is relatively straightforward
using PyTorch. In this recipe, we will experiment with saving and
loading models across CPUs and GPUs.

Setup
-----

In order for every code block to run properly in this recipe, you must
first change the runtime to “GPU” or higher. Once you do, we need to
install ``torch`` if it isn’t already available.

::

   pip install torch


Steps
-----

1. Import all necessary libraries for loading our data
2. Define and intialize the neural network
3. Save on a GPU, load on a CPU
4. Save on a GPU, load on a GPU
5. Save on a CPU, load on a GPU
6. Saving and loading ``DataParallel`` models

1. Import necessary libraries for loading our data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For this recipe, we will use ``torch`` and its subsidiaries ``torch.nn``
and ``torch.optim``.


2. Define and intialize the neural network
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For sake of example, we will create a neural network for training
images. To learn more see the Defining a Neural Network recipe.


3. Save on GPU, Load on CPU
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When loading a model on a CPU that was trained with a GPU, pass
``torch.device('cpu')`` to the ``map_location`` argument in the
``torch.load()`` function.



.. code-block:: default


    # Specify a path to save to


    # Save


    # Load






In this case, the storages underlying the tensors are dynamically
remapped to the CPU device using the ``map_location`` argument.

4. Save on GPU, Load on GPU
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When loading a model on a GPU that was trained and saved on GPU, simply
convert the initialized model to a CUDA optimized model using
``model.to(torch.device('cuda'))``.

Be sure to use the ``.to(torch.device('cuda'))`` function on all model
inputs to prepare the data for the model.



.. code-block:: default


    # Save


    # Load







Note that calling ``my_tensor.to(device)`` returns a new copy of
``my_tensor`` on GPU. It does NOT overwrite ``my_tensor``. Therefore,
remember to manually overwrite tensors:
``my_tensor = my_tensor.to(torch.device('cuda'))``.

5. Save on CPU, Load on GPU
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When loading a model on a GPU that was trained and saved on CPU, set the
``map_location`` argument in the ``torch.load()`` function to
``cuda:device_id``. This loads the model to a given GPU device.

Be sure to call ``model.to(torch.device('cuda'))`` to convert the
model’s parameter tensors to CUDA tensors.

Finally, also be sure to use the ``.to(torch.device('cuda'))`` function
on all model inputs to prepare the data for the CUDA optimized model.



.. code-block:: default


    # Save


    # Load


    # Choose whatever GPU device number you want

    # Make sure to call input = input.to(device) on any input tensors that you feed to the model




6. Saving ``torch.nn.DataParallel`` Models
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

``torch.nn.DataParallel`` is a model wrapper that enables parallel GPU
utilization.

To save a ``DataParallel`` model generically, save the
``model.module.state_dict()``. This way, you have the flexibility to
load the model any way you want to any device you want.



.. code-block:: default


    # Save


    # Load to whatever device you want



Congratulations! You have successfully saved and loaded models across
devices in PyTorch.

Learn More
----------

Take a look at these other recipes to continue your learning:

-  TBD
-  TBD



.. code-block:: default


    # %%%%%%RUNNABLE_CODE_REMOVED%%%%%%

.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_recipes_recipes_save_load_across_devices.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: save_load_across_devices.py <save_load_across_devices.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: save_load_across_devices.ipynb <save_load_across_devices.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
