.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_recipes_recipes_saving_and_loading_a_general_checkpoint.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_recipes_recipes_saving_and_loading_a_general_checkpoint.py:


Saving and loading a general checkpoint in PyTorch
==================================================
Saving and loading a general checkpoint model for inference or 
resuming training can be helpful for picking up where you last left off.
When saving a general checkpoint, you must save more than just the
model’s state_dict. It is important to also save the optimizer’s
state_dict, as this contains buffers and parameters that are updated as
the model trains. Other items that you may want to save are the epoch
you left off on, the latest recorded training loss, external
``torch.nn.Embedding`` layers, and more, based on your own algorithm.

Introduction
------------
To save multiple checkpoints, you must organize them in a dictionary and
use ``torch.save()`` to serialize the dictionary. A common PyTorch
convention is to save these checkpoints using the ``.tar`` file
extension. To load the items, first initialize the model and optimizer,
then load the dictionary locally using torch.load(). From here, you can
easily access the saved items by simply querying the dictionary as you
would expect.

In this recipe, we will explore how to save and load multiple
checkpoints.

Setup
-----
Before we begin, we need to install ``torch`` if it isn’t already
available.

::

   pip install torch



Steps
-----

1. Import all necessary libraries for loading our data
2. Define and intialize the neural network
3. Initialize the optimizer
4. Save the general checkpoint
5. Load the general checkpoint

1. Import necessary libraries for loading our data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For this recipe, we will use ``torch`` and its subsidiaries ``torch.nn``
and ``torch.optim``.


2. Define and intialize the neural network
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For sake of example, we will create a neural network for training
images. To learn more see the Defining a Neural Network recipe.


3. Initialize the optimizer
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We will use SGD with momentum.


4. Save the general checkpoint
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Collect all relevant information and build your dictionary.



.. code-block:: default


    # Additional information













5. Load the general checkpoint
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Remember to first initialize the model and optimizer, then load the
dictionary locally.



.. code-block:: default












    # - or -




You must call ``model.eval()`` to set dropout and batch normalization
layers to evaluation mode before running inference. Failing to do this
will yield inconsistent inference results.

If you wish to resuming training, call ``model.train()`` to ensure these
layers are in training mode.

Congratulations! You have successfully saved and loaded a general
checkpoint for inference and/or resuming training in PyTorch.

Learn More
----------

Take a look at these other recipes to continue your learning:

-  TBD
-  TBD


.. code-block:: default


    # %%%%%%RUNNABLE_CODE_REMOVED%%%%%%

.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_recipes_recipes_saving_and_loading_a_general_checkpoint.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: saving_and_loading_a_general_checkpoint.py <saving_and_loading_a_general_checkpoint.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: saving_and_loading_a_general_checkpoint.ipynb <saving_and_loading_a_general_checkpoint.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
