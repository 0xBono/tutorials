.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:


.. code-block:: default

    from functools import partial
    import numpy as np
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.tune import CLIReporter
    from ray.tune.schedulers import ASHAScheduler







Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.


.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform)

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform)

        return trainset, testset







Configurable neural network
---------------------------
We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:


.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(-1, 16 * 5 * 5)
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x







The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.
As you can guess, the ``config`` parameter will receive the hyperparameters we would like to
train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies
the directory where we load and store the data, so multiple runs can share the same data source.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    if checkpoint_dir:
        model_state, optimizer_state = torch.load(
            os.path.join(checkpoint_dir, "checkpoint"))
        net.load_state_dict(model_state)
        optimizer.load_state_dict(optimizer_state)

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    with tune.checkpoint_dir(epoch) as checkpoint_dir:
        path = os.path.join(checkpoint_dir, "checkpoint")
        torch.save((net.state_dict(), optimizer.state_dict()), path)

    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:


.. code-block:: default



    def train_cifar(config, checkpoint_dir=None, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        if checkpoint_dir:
            model_state, optimizer_state = torch.load(
                os.path.join(checkpoint_dir, "checkpoint"))
            net.load_state_dict(model_state)
            optimizer.load_state_dict(optimizer_state)

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs])

        trainloader = torch.utils.data.DataLoader(
            train_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)
        valloader = torch.utils.data.DataLoader(
            val_subset,
            batch_size=int(config["batch_size"]),
            shuffle=True,
            num_workers=8)

        for epoch in range(10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print("[%d, %5d] loss: %.3f" % (epoch + 1, i + 1,
                                                    running_loss / epoch_steps))
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            with tune.checkpoint_dir(epoch) as checkpoint_dir:
                path = os.path.join(checkpoint_dir, "checkpoint")
                torch.save((net.state_dict(), optimizer.state_dict()), path)

            tune.report(loss=(val_loss / val_steps), accuracy=correct / total)
        print("Finished Training")







As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:


.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2)

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total







The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.sample_from()`` function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:


.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16])
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2)
        reporter = CLIReporter(
            # parameter_columns=["l1", "l2", "lr", "batch_size"],
            metric_columns=["loss", "accuracy", "training_iteration"])
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
            progress_reporter=reporter)

        best_trial = result.get_best_trial("loss", "min", "last")
        print("Best trial config: {}".format(best_trial.config))
        print("Best trial final validation loss: {}".format(
            best_trial.last_result["loss"]))
        print("Best trial final validation accuracy: {}".format(
            best_trial.last_result["accuracy"]))

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint_dir = best_trial.checkpoint.value
        model_state, optimizer_state = torch.load(os.path.join(
            best_checkpoint_dir, "checkpoint"))
        best_trained_model.load_state_dict(model_state)

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 1/10 (1 RUNNING)
    +---------------------+----------+-------+--------------+------+------+-----------+
    | Trial name          | status   | loc   |   batch_size |   l1 |   l2 |        lr |
    |---------------------+----------+-------+--------------+------+------+-----------|
    | DEFAULT_250ec_00000 | RUNNING  |       |            4 |    8 |  256 | 0.0694832 |
    +---------------------+----------+-------+--------------+------+------+-----------+


    [2m[36m(pid=1438)[0m Files already downloaded and verified
    [2m[36m(pid=1415)[0m Files already downloaded and verified
    [2m[36m(pid=1431)[0m Files already downloaded and verified
    [2m[36m(pid=1440)[0m Files already downloaded and verified
    [2m[36m(pid=1419)[0m Files already downloaded and verified
    [2m[36m(pid=1381)[0m Files already downloaded and verified
    [2m[36m(pid=1421)[0m Files already downloaded and verified
    [2m[36m(pid=1427)[0m Files already downloaded and verified
    [2m[36m(pid=1389)[0m Files already downloaded and verified
    [2m[36m(pid=1443)[0m Files already downloaded and verified
    [2m[36m(pid=1438)[0m Files already downloaded and verified
    [2m[36m(pid=1415)[0m Files already downloaded and verified
    [2m[36m(pid=1431)[0m Files already downloaded and verified
    [2m[36m(pid=1440)[0m Files already downloaded and verified
    [2m[36m(pid=1419)[0m Files already downloaded and verified
    [2m[36m(pid=1381)[0m Files already downloaded and verified
    [2m[36m(pid=1421)[0m Files already downloaded and verified
    [2m[36m(pid=1427)[0m Files already downloaded and verified
    [2m[36m(pid=1389)[0m Files already downloaded and verified
    [2m[36m(pid=1443)[0m Files already downloaded and verified
    [2m[36m(pid=1415)[0m [1,  2000] loss: 2.344
    [2m[36m(pid=1419)[0m [1,  2000] loss: 2.310
    [2m[36m(pid=1431)[0m [1,  2000] loss: 2.342
    [2m[36m(pid=1421)[0m [1,  2000] loss: 2.132
    [2m[36m(pid=1381)[0m [1,  2000] loss: 2.316
    [2m[36m(pid=1440)[0m [1,  2000] loss: 2.297
    [2m[36m(pid=1389)[0m [1,  2000] loss: 2.317
    [2m[36m(pid=1427)[0m [1,  2000] loss: 1.896
    [2m[36m(pid=1438)[0m [1,  2000] loss: 2.083
    [2m[36m(pid=1443)[0m [1,  2000] loss: 2.270
    Result for DEFAULT_250ec_00001:
      accuracy: 0.3665
      date: 2020-11-11_23-18-30
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 1.7056957782745361
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 27.350802659988403
      time_this_iter_s: 27.350802659988403
      time_total_s: 27.350802659988403
      timestamp: 1605136710
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 9.4/240.1 GiB
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.7056957782745361
    Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (10 RUNNING)
    +---------------------+----------+-----------------+--------------+------+------+-------------+--------+------------+----------------------+
    | Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |
    |---------------------+----------+-----------------+--------------+------+------+-------------+--------+------------+----------------------|
    | DEFAULT_250ec_00000 | RUNNING  |                 |            4 |    8 |  256 | 0.0694832   |        |            |                      |
    | DEFAULT_250ec_00001 | RUNNING  | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.7057 |     0.3665 |                    1 |
    | DEFAULT_250ec_00002 | RUNNING  |                 |           16 |    8 |   16 | 0.000641015 |        |            |                      |
    | DEFAULT_250ec_00003 | RUNNING  |                 |            4 |    8 |    4 | 0.060436    |        |            |                      |
    | DEFAULT_250ec_00004 | RUNNING  |                 |            8 |    4 |  256 | 0.000345941 |        |            |                      |
    | DEFAULT_250ec_00005 | RUNNING  |                 |            4 |   16 |    8 | 0.0288806   |        |            |                      |
    | DEFAULT_250ec_00006 | RUNNING  |                 |            4 |  128 |   64 | 0.0125047   |        |            |                      |
    | DEFAULT_250ec_00007 | RUNNING  |                 |            8 |  256 |   64 | 0.00407155  |        |            |                      |
    | DEFAULT_250ec_00008 | RUNNING  |                 |            8 |    4 |  256 | 0.0367503   |        |            |                      |
    | DEFAULT_250ec_00009 | RUNNING  |                 |            8 |   16 |    4 | 0.000508746 |        |            |                      |
    +---------------------+----------+-----------------+--------------+------+------+-------------+--------+------------+----------------------+


    [2m[36m(pid=1415)[0m [1,  4000] loss: 1.174
    [2m[36m(pid=1419)[0m [1,  4000] loss: 1.159
    Result for DEFAULT_250ec_00002:
      accuracy: 0.2618
      date: 2020-11-11_23-18-31
      done: true
      experiment_id: 552d8525395545a6b1bf7582e0fc6bbb
      experiment_tag: 2_batch_size=16,l1=8,l2=16,lr=0.00064102
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 2.0207590547561645
      node_ip: 172.17.0.2
      pid: 1443
      should_checkpoint: true
      time_since_restore: 27.885326147079468
      time_this_iter_s: 27.885326147079468
      time_total_s: 27.885326147079468
      timestamp: 1605136711
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00002
  
    [2m[36m(pid=1431)[0m [1,  4000] loss: 1.168
    [2m[36m(pid=1421)[0m [1,  4000] loss: 1.029
    [2m[36m(pid=1381)[0m [1,  4000] loss: 1.157
    [2m[36m(pid=1389)[0m [1,  4000] loss: 1.142
    [2m[36m(pid=1440)[0m [1,  4000] loss: 1.024
    [2m[36m(pid=1427)[0m [1,  4000] loss: 0.787
    [2m[36m(pid=1415)[0m [1,  6000] loss: 0.780
    [2m[36m(pid=1419)[0m [1,  6000] loss: 0.773
    [2m[36m(pid=1431)[0m [1,  6000] loss: 0.778
    [2m[36m(pid=1421)[0m [1,  6000] loss: 0.675
    Result for DEFAULT_250ec_00008:
      accuracy: 0.099
      date: 2020-11-11_23-18-45
      done: true
      experiment_id: b5ce835fbee44d85aeafd04308b92736
      experiment_tag: 8_batch_size=8,l1=4,l2=256,lr=0.03675
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 2.313268851661682
      node_ip: 172.17.0.2
      pid: 1381
      should_checkpoint: true
      time_since_restore: 41.85536766052246
      time_this_iter_s: 41.85536766052246
      time_total_s: 41.85536766052246
      timestamp: 1605136725
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00008
  
    == Status ==
    Memory usage on this node: 8.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0207590547561645
    Resources requested: 18/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (9 RUNNING, 1 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00000 | RUNNING    |                 |            4 |    8 |  256 | 0.0694832   |         |            |                      |
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.7057  |     0.3665 |                    1 |
    | DEFAULT_250ec_00003 | RUNNING    |                 |            4 |    8 |    4 | 0.060436    |         |            |                      |
    | DEFAULT_250ec_00004 | RUNNING    |                 |            8 |    4 |  256 | 0.000345941 |         |            |                      |
    | DEFAULT_250ec_00005 | RUNNING    |                 |            4 |   16 |    8 | 0.0288806   |         |            |                      |
    | DEFAULT_250ec_00006 | RUNNING    |                 |            4 |  128 |   64 | 0.0125047   |         |            |                      |
    | DEFAULT_250ec_00007 | RUNNING    |                 |            8 |  256 |   64 | 0.00407155  |         |            |                      |
    | DEFAULT_250ec_00008 | RUNNING    | 172.17.0.2:1381 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | RUNNING    |                 |            8 |   16 |    4 | 0.000508746 |         |            |                      |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_250ec_00009:
      accuracy: 0.2129
      date: 2020-11-11_23-18-45
      done: true
      experiment_id: fb2c161d0b73480e9d4566cc8160dc8c
      experiment_tag: 9_batch_size=8,l1=16,l2=4,lr=0.00050875
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 2.1568080434799195
      node_ip: 172.17.0.2
      pid: 1389
      should_checkpoint: true
      time_since_restore: 41.93644571304321
      time_this_iter_s: 41.93644571304321
      time_total_s: 41.93644571304321
      timestamp: 1605136725
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00009
  
    Result for DEFAULT_250ec_00004:
      accuracy: 0.306
      date: 2020-11-11_23-18-45
      done: false
      experiment_id: 207804227a9d42cdbc046c1e9c9be381
      experiment_tag: 4_batch_size=8,l1=4,l2=256,lr=0.00034594
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 1.8735858739852904
      node_ip: 172.17.0.2
      pid: 1440
      should_checkpoint: true
      time_since_restore: 42.26770544052124
      time_this_iter_s: 42.26770544052124
      time_total_s: 42.26770544052124
      timestamp: 1605136725
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00004
  
    [2m[36m(pid=1438)[0m [2,  2000] loss: 1.580
    Result for DEFAULT_250ec_00007:
      accuracy: 0.4484
      date: 2020-11-11_23-18-47
      done: false
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 1.530622979426384
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 43.76608347892761
      time_this_iter_s: 43.76608347892761
      time_total_s: 43.76608347892761
      timestamp: 1605136727
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00007
  
    Result for DEFAULT_250ec_00001:
      accuracy: 0.468
      date: 2020-11-11_23-18-53
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 2
      loss: 1.4574017480850219
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 50.16190266609192
      time_this_iter_s: 22.811100006103516
      time_total_s: 50.16190266609192
      timestamp: 1605136733
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 7.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4574017480850219 | Iter 1.000: -1.9471724643707273
    Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00000 | RUNNING    |                 |            4 |    8 |  256 | 0.0694832   |         |            |                      |
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.4574  |     0.468  |                    2 |
    | DEFAULT_250ec_00003 | RUNNING    |                 |            4 |    8 |    4 | 0.060436    |         |            |                      |
    | DEFAULT_250ec_00004 | RUNNING    | 172.17.0.2:1440 |            8 |    4 |  256 | 0.000345941 | 1.87359 |     0.306  |                    1 |
    | DEFAULT_250ec_00005 | RUNNING    |                 |            4 |   16 |    8 | 0.0288806   |         |            |                      |
    | DEFAULT_250ec_00006 | RUNNING    |                 |            4 |  128 |   64 | 0.0125047   |         |            |                      |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.53062 |     0.4484 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1415)[0m [1,  8000] loss: 0.585
    [2m[36m(pid=1419)[0m [1,  8000] loss: 0.579
    [2m[36m(pid=1431)[0m [1,  8000] loss: 0.584
    [2m[36m(pid=1421)[0m [1,  8000] loss: 0.512
    [2m[36m(pid=1440)[0m [2,  2000] loss: 1.752
    [2m[36m(pid=1427)[0m [2,  2000] loss: 1.429
    [2m[36m(pid=1415)[0m [1, 10000] loss: 0.468
    [2m[36m(pid=1431)[0m [1, 10000] loss: 0.467
    [2m[36m(pid=1419)[0m [1, 10000] loss: 0.464
    [2m[36m(pid=1421)[0m [1, 10000] loss: 0.431
    [2m[36m(pid=1438)[0m [3,  2000] loss: 1.404
    [2m[36m(pid=1440)[0m [2,  4000] loss: 0.814
    Result for DEFAULT_250ec_00000:
      accuracy: 0.0942
      date: 2020-11-11_23-19-23
      done: true
      experiment_id: add16d166498493c8f1994b22a1af346
      experiment_tag: 0_batch_size=4,l1=8,l2=256,lr=0.069483
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 2.362865458726883
      node_ip: 172.17.0.2
      pid: 1415
      should_checkpoint: true
      time_since_restore: 80.54516243934631
      time_this_iter_s: 80.54516243934631
      time_total_s: 80.54516243934631
      timestamp: 1605136763
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00000
  
    == Status ==
    Memory usage on this node: 7.7/240.1 GiB
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4574017480850219 | Iter 1.000: -2.0207590547561645
    Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00000 | RUNNING    | 172.17.0.2:1415 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.4574  |     0.468  |                    2 |
    | DEFAULT_250ec_00003 | RUNNING    |                 |            4 |    8 |    4 | 0.060436    |         |            |                      |
    | DEFAULT_250ec_00004 | RUNNING    | 172.17.0.2:1440 |            8 |    4 |  256 | 0.000345941 | 1.87359 |     0.306  |                    1 |
    | DEFAULT_250ec_00005 | RUNNING    |                 |            4 |   16 |    8 | 0.0288806   |         |            |                      |
    | DEFAULT_250ec_00006 | RUNNING    |                 |            4 |  128 |   64 | 0.0125047   |         |            |                      |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.53062 |     0.4484 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_250ec_00003:
      accuracy: 0.1001
      date: 2020-11-11_23-19-23
      done: true
      experiment_id: 1f5b2d701cf94d0c8bfa2eee25327307
      experiment_tag: 3_batch_size=4,l1=8,l2=4,lr=0.060436
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 2.3231278891563414
      node_ip: 172.17.0.2
      pid: 1431
      should_checkpoint: true
      time_since_restore: 80.62914299964905
      time_this_iter_s: 80.62914299964905
      time_total_s: 80.62914299964905
      timestamp: 1605136763
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00003
  
    Result for DEFAULT_250ec_00005:
      accuracy: 0.1017
      date: 2020-11-11_23-19-24
      done: true
      experiment_id: 51e5c383bf9049b2a2a32547679c7d5d
      experiment_tag: 5_batch_size=4,l1=16,l2=8,lr=0.028881
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 2.3120034555435183
      node_ip: 172.17.0.2
      pid: 1419
      should_checkpoint: true
      time_since_restore: 80.87818765640259
      time_this_iter_s: 80.87818765640259
      time_total_s: 80.87818765640259
      timestamp: 1605136764
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00005
  
    [2m[36m(pid=1427)[0m [2,  4000] loss: 0.683
    Result for DEFAULT_250ec_00001:
      accuracy: 0.5
      date: 2020-11-11_23-19-26
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 3
      loss: 1.3731698335647582
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 83.42231726646423
      time_this_iter_s: 33.260414600372314
      time_total_s: 83.42231726646423
      timestamp: 1605136766
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 250ec_00001
  
    Result for DEFAULT_250ec_00006:
      accuracy: 0.1968
      date: 2020-11-11_23-19-26
      done: false
      experiment_id: c367ededafa34202ba588ff38ac21ae6
      experiment_tag: 6_batch_size=4,l1=128,l2=64,lr=0.012505
      hostname: 6b14ed07f84c
      iterations_since_restore: 1
      loss: 2.0728264351844787
      node_ip: 172.17.0.2
      pid: 1421
      should_checkpoint: true
      time_since_restore: 83.49589467048645
      time_this_iter_s: 83.49589467048645
      time_total_s: 83.49589467048645
      timestamp: 1605136766
      timesteps_since_restore: 0
      training_iteration: 1
      trial_id: 250ec_00006
  
    Result for DEFAULT_250ec_00004:
      accuracy: 0.4161
      date: 2020-11-11_23-19-31
      done: true
      experiment_id: 207804227a9d42cdbc046c1e9c9be381
      experiment_tag: 4_batch_size=8,l1=4,l2=256,lr=0.00034594
      hostname: 6b14ed07f84c
      iterations_since_restore: 2
      loss: 1.5541968680381775
      node_ip: 172.17.0.2
      pid: 1440
      should_checkpoint: true
      time_since_restore: 87.89934706687927
      time_this_iter_s: 45.63164162635803
      time_total_s: 87.89934706687927
      timestamp: 1605136771
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 250ec_00004
  
    == Status ==
    Memory usage on this node: 6.0/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.37317 |     0.5    |                    3 |
    | DEFAULT_250ec_00004 | RUNNING    | 172.17.0.2:1440 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00006 | RUNNING    | 172.17.0.2:1421 |            4 |  128 |   64 | 0.0125047   | 2.07283 |     0.1968 |                    1 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.53062 |     0.4484 |                    1 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_250ec_00007:
      accuracy: 0.5334
      date: 2020-11-11_23-19-34
      done: false
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 2
      loss: 1.3223947215318679
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 91.19547295570374
      time_this_iter_s: 47.42938947677612
      time_total_s: 91.19547295570374
      timestamp: 1605136774
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 250ec_00007
  
    [2m[36m(pid=1421)[0m [2,  2000] loss: 2.173
    [2m[36m(pid=1438)[0m [4,  2000] loss: 1.305
    [2m[36m(pid=1427)[0m [3,  2000] loss: 1.253
    Result for DEFAULT_250ec_00001:
      accuracy: 0.5386
      date: 2020-11-11_23-19-46
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 4
      loss: 1.2626098398208618
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 103.55269527435303
      time_this_iter_s: 20.130378007888794
      time_total_s: 103.55269527435303
      timestamp: 1605136786
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 5.4/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.2626098398208618 | Iter 2.000: -1.4574017480850219 | Iter 1.000: -2.114817239332199
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.26261 |     0.5386 |                    4 |
    | DEFAULT_250ec_00006 | RUNNING    | 172.17.0.2:1421 |            4 |  128 |   64 | 0.0125047   | 2.07283 |     0.1968 |                    1 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.32239 |     0.5334 |                    2 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1421)[0m [2,  4000] loss: 1.155
    [2m[36m(pid=1427)[0m [3,  4000] loss: 0.630
    [2m[36m(pid=1438)[0m [5,  2000] loss: 1.231
    [2m[36m(pid=1421)[0m [2,  6000] loss: 0.770
    Result for DEFAULT_250ec_00001:
      accuracy: 0.5663
      date: 2020-11-11_23-20-07
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 5
      loss: 1.2000580348968506
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 123.84536933898926
      time_this_iter_s: 20.29267406463623
      time_total_s: 123.84536933898926
      timestamp: 1605136807
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 5.4/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.2626098398208618 | Iter 2.000: -1.4574017480850219 | Iter 1.000: -2.114817239332199
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.20006 |     0.5663 |                    5 |
    | DEFAULT_250ec_00006 | RUNNING    | 172.17.0.2:1421 |            4 |  128 |   64 | 0.0125047   | 2.07283 |     0.1968 |                    1 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.32239 |     0.5334 |                    2 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_250ec_00007:
      accuracy: 0.5519
      date: 2020-11-11_23-20-07
      done: false
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 3
      loss: 1.2816016721963883
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 124.28511214256287
      time_this_iter_s: 33.08963918685913
      time_total_s: 124.28511214256287
      timestamp: 1605136807
      timesteps_since_restore: 0
      training_iteration: 3
      trial_id: 250ec_00007
  
    [2m[36m(pid=1421)[0m [2,  8000] loss: 0.578
    [2m[36m(pid=1427)[0m [4,  2000] loss: 1.171
    [2m[36m(pid=1438)[0m [6,  2000] loss: 1.162
    [2m[36m(pid=1421)[0m [2, 10000] loss: 0.462
    Result for DEFAULT_250ec_00001:
      accuracy: 0.5673
      date: 2020-11-11_23-20-27
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 6
      loss: 1.219904902458191
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 143.91903948783875
      time_this_iter_s: 20.073670148849487
      time_total_s: 143.91903948783875
      timestamp: 1605136827
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 5.4/240.1 GiB
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.2626098398208618 | Iter 2.000: -1.4574017480850219 | Iter 1.000: -2.114817239332199
    Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.2199  |     0.5673 |                    6 |
    | DEFAULT_250ec_00006 | RUNNING    | 172.17.0.2:1421 |            4 |  128 |   64 | 0.0125047   | 2.07283 |     0.1968 |                    1 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.2816  |     0.5519 |                    3 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1427)[0m [4,  4000] loss: 0.586
    Result for DEFAULT_250ec_00006:
      accuracy: 0.1018
      date: 2020-11-11_23-20-31
      done: true
      experiment_id: c367ededafa34202ba588ff38ac21ae6
      experiment_tag: 6_batch_size=4,l1=128,l2=64,lr=0.012505
      hostname: 6b14ed07f84c
      iterations_since_restore: 2
      loss: 2.3112216209411622
      node_ip: 172.17.0.2
      pid: 1421
      should_checkpoint: true
      time_since_restore: 147.8799364566803
      time_this_iter_s: 64.38404178619385
      time_total_s: 147.8799364566803
      timestamp: 1605136831
      timesteps_since_restore: 0
      training_iteration: 2
      trial_id: 250ec_00006
  
    Result for DEFAULT_250ec_00007:
      accuracy: 0.5654
      date: 2020-11-11_23-20-40
      done: false
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 4
      loss: 1.2545833014845849
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 157.33082747459412
      time_this_iter_s: 33.04571533203125
      time_total_s: 157.33082747459412
      timestamp: 1605136840
      timesteps_since_restore: 0
      training_iteration: 4
      trial_id: 250ec_00007
  
    == Status ==
    Memory usage on this node: 4.8/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: None | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.2199  |     0.5673 |                    6 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.25458 |     0.5654 |                    4 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1438)[0m [7,  2000] loss: 1.121
    Result for DEFAULT_250ec_00001:
      accuracy: 0.5922
      date: 2020-11-11_23-20-47
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 7
      loss: 1.153710903120041
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 163.75402450561523
      time_this_iter_s: 19.83498501777649
      time_total_s: 163.75402450561523
      timestamp: 1605136847
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 4.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: None | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.15371 |     0.5922 |                    7 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.25458 |     0.5654 |                    4 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1427)[0m [5,  2000] loss: 1.078
    [2m[36m(pid=1438)[0m [8,  2000] loss: 1.079
    [2m[36m(pid=1427)[0m [5,  4000] loss: 0.550
    Result for DEFAULT_250ec_00001:
      accuracy: 0.5855
      date: 2020-11-11_23-21-06
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 8
      loss: 1.1761146993637086
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 183.5263500213623
      time_this_iter_s: 19.77232551574707
      time_total_s: 183.5263500213623
      timestamp: 1605136866
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 4.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1761146993637086 | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.17611 |     0.5855 |                    8 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.25458 |     0.5654 |                    4 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_250ec_00007:
      accuracy: 0.57
      date: 2020-11-11_23-21-13
      done: false
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 5
      loss: 1.255101065504551
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 189.91902899742126
      time_this_iter_s: 32.58820152282715
      time_total_s: 189.91902899742126
      timestamp: 1605136873
      timesteps_since_restore: 0
      training_iteration: 5
      trial_id: 250ec_00007
  
    == Status ==
    Memory usage on this node: 4.8/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1761146993637086 | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.17611 |     0.5855 |                    8 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.2551  |     0.57   |                    5 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1438)[0m [9,  2000] loss: 1.049
    [2m[36m(pid=1427)[0m [6,  2000] loss: 1.008
    Result for DEFAULT_250ec_00001:
      accuracy: 0.6076
      date: 2020-11-11_23-21-26
      done: false
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 9
      loss: 1.1237835050821305
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 203.45087695121765
      time_this_iter_s: 19.924526929855347
      time_total_s: 203.45087695121765
      timestamp: 1605136886
      timesteps_since_restore: 0
      training_iteration: 9
      trial_id: 250ec_00001
  
    == Status ==
    Memory usage on this node: 4.9/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1761146993637086 | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.12378 |     0.6076 |                    9 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.2551  |     0.57   |                    5 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1427)[0m [6,  4000] loss: 0.529
    [2m[36m(pid=1438)[0m [10,  2000] loss: 1.028
    Result for DEFAULT_250ec_00007:
      accuracy: 0.5792
      date: 2020-11-11_23-21-46
      done: false
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 6
      loss: 1.266587928056717
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 222.71975564956665
      time_this_iter_s: 32.800726652145386
      time_total_s: 222.71975564956665
      timestamp: 1605136906
      timesteps_since_restore: 0
      training_iteration: 6
      trial_id: 250ec_00007
  
    == Status ==
    Memory usage on this node: 4.8/240.1 GiB
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1761146993637086 | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00001 | RUNNING    | 172.17.0.2:1438 |           16 |   32 |   16 | 0.00221016  | 1.12378 |     0.6076 |                    9 |
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.26659 |     0.5792 |                    6 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    Result for DEFAULT_250ec_00001:
      accuracy: 0.6077
      date: 2020-11-11_23-21-46
      done: true
      experiment_id: 1b88d37992ad4b8da24778aff6bef7d9
      experiment_tag: 1_batch_size=16,l1=32,l2=16,lr=0.0022102
      hostname: 6b14ed07f84c
      iterations_since_restore: 10
      loss: 1.137229550933838
      node_ip: 172.17.0.2
      pid: 1438
      should_checkpoint: true
      time_since_restore: 223.1378047466278
      time_this_iter_s: 19.686927795410156
      time_total_s: 223.1378047466278
      timestamp: 1605136906
      timesteps_since_restore: 0
      training_iteration: 10
      trial_id: 250ec_00001
  
    [2m[36m(pid=1427)[0m [7,  2000] loss: 0.949
    [2m[36m(pid=1427)[0m [7,  4000] loss: 0.507
    Result for DEFAULT_250ec_00007:
      accuracy: 0.5816
      date: 2020-11-11_23-22-18
      done: false
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 7
      loss: 1.246183581662178
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 254.84026384353638
      time_this_iter_s: 32.12050819396973
      time_total_s: 254.84026384353638
      timestamp: 1605136938
      timesteps_since_restore: 0
      training_iteration: 7
      trial_id: 250ec_00007
  
    == Status ==
    Memory usage on this node: 4.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=9
    Bracket: Iter 8.000: -1.1761146993637086 | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.24618 |     0.5816 |                    7 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00001 | TERMINATED |                 |           16 |   32 |   16 | 0.00221016  | 1.13723 |     0.6077 |                   10 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    [2m[36m(pid=1427)[0m [8,  2000] loss: 0.938
    [2m[36m(pid=1427)[0m [8,  4000] loss: 0.493
    Result for DEFAULT_250ec_00007:
      accuracy: 0.5654
      date: 2020-11-11_23-22-50
      done: true
      experiment_id: 60e042453fe14e1d8804b0930706c269
      experiment_tag: 7_batch_size=8,l1=256,l2=64,lr=0.0040715
      hostname: 6b14ed07f84c
      iterations_since_restore: 8
      loss: 1.3319588543891907
      node_ip: 172.17.0.2
      pid: 1427
      should_checkpoint: true
      time_since_restore: 286.95401263237
      time_this_iter_s: 32.11374878883362
      time_total_s: 286.95401263237
      timestamp: 1605136970
      timesteps_since_restore: 0
      training_iteration: 8
      trial_id: 250ec_00007
  
    == Status ==
    Memory usage on this node: 4.2/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2540367768764495 | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00007 | RUNNING    | 172.17.0.2:1427 |            8 |  256 |   64 | 0.00407155  | 1.33196 |     0.5654 |                    8 |
    | DEFAULT_250ec_00000 | TERMINATED |                 |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00001 | TERMINATED |                 |           16 |   32 |   16 | 0.00221016  | 1.13723 |     0.6077 |                   10 |
    | DEFAULT_250ec_00002 | TERMINATED |                 |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |                 |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |                 |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |                 |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |                 |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00008 | TERMINATED |                 |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |                 |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


    == Status ==
    Memory usage on this node: 4.1/240.1 GiB
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.2540367768764495 | Iter 4.000: -1.2585965706527233 | Iter 2.000: -1.5057993080615997 | Iter 1.000: -2.114817239332199
    Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.37 GiB objects
    Result logdir: /var/lib/jenkins/ray_results/DEFAULT_2020-11-11_23-18-02
    Number of trials: 10/10 (10 TERMINATED)
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
    | Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
    |---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
    | DEFAULT_250ec_00000 | TERMINATED |       |            4 |    8 |  256 | 0.0694832   | 2.36287 |     0.0942 |                    1 |
    | DEFAULT_250ec_00001 | TERMINATED |       |           16 |   32 |   16 | 0.00221016  | 1.13723 |     0.6077 |                   10 |
    | DEFAULT_250ec_00002 | TERMINATED |       |           16 |    8 |   16 | 0.000641015 | 2.02076 |     0.2618 |                    1 |
    | DEFAULT_250ec_00003 | TERMINATED |       |            4 |    8 |    4 | 0.060436    | 2.32313 |     0.1001 |                    1 |
    | DEFAULT_250ec_00004 | TERMINATED |       |            8 |    4 |  256 | 0.000345941 | 1.5542  |     0.4161 |                    2 |
    | DEFAULT_250ec_00005 | TERMINATED |       |            4 |   16 |    8 | 0.0288806   | 2.312   |     0.1017 |                    1 |
    | DEFAULT_250ec_00006 | TERMINATED |       |            4 |  128 |   64 | 0.0125047   | 2.31122 |     0.1018 |                    2 |
    | DEFAULT_250ec_00007 | TERMINATED |       |            8 |  256 |   64 | 0.00407155  | 1.33196 |     0.5654 |                    8 |
    | DEFAULT_250ec_00008 | TERMINATED |       |            8 |    4 |  256 | 0.0367503   | 2.31327 |     0.099  |                    1 |
    | DEFAULT_250ec_00009 | TERMINATED |       |            8 |   16 |    4 | 0.000508746 | 2.15681 |     0.2129 |                    1 |
    +---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


    Best trial config: {'l1': 32, 'l2': 16, 'lr': 0.002210161023353882, 'batch_size': 16}
    Best trial final validation loss: 1.137229550933838
    Best trial final validation accuracy: 0.6077
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.609


If you run the code, an example output could look like this:

.. code-block::

    Number of trials: 10 (10 TERMINATED)
    +-----+------+------+-------------+--------------+---------+------------+--------------------+
    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |
    |-----+------+------+-------------+--------------+---------+------------+--------------------|
    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |
    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |
    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |
    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |
    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |
    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |
    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |
    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |
    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |
    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |
    +-----+------+------+-------------+--------------+---------+------------+--------------------+


    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}
    Best trial final validation loss: 1.181501
    Best trial final validation accuracy: 0.5836
    Best trial test set accuracy: 0.5806

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 5 minutes  12.255 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
