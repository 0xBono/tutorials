
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Hyperparameter tuning with Ray Tune — PyTorch Tutorials 1.6.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial"/>
<link href="../advanced/dispatcher.html" rel="prev" title="Registering a Dispatched Operator in C++"/>
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<div class="ecosystem-dropdown">
<a data-toggle="ecosystem-dropdown" id="dropdownMenuButton">
                Ecosystem
              </a>
<div class="ecosystem-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
<span class="dropdown-title">Tools &amp; Libraries</span>
<p>Explore the ecosystem of tools and libraries</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<div class="resources-dropdown">
<a data-toggle="resources-dropdown" id="resourcesDropdownButton">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.6.0
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption"><span class="caption-text">Image/Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_preprocessing_tutorial.html">torchaudio Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_sentiment_ngrams_tutorial.html">Text Classification with TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtext_translation_tutorial.html">Language Translation with TorchText</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
</ul>
<p class="caption"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/named_tensor_tutorial.html">(prototype) Introduction to Named Tensors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="aws_distributed_training_tutorial.html">(advanced) PyTorch 1.0 Distributed Trainer with Amazon AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Hyperparameter tuning with Ray Tune</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/hyperparameter_tuning_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/hyperparameter_tuning_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="hyperparameter-tuning-with-ray-tune">
<span id="sphx-glr-beginner-hyperparameter-tuning-tutorial-py"></span><h1>Hyperparameter tuning with Ray Tune<a class="headerlink" href="#hyperparameter-tuning-with-ray-tune" title="Permalink to this headline">¶</a></h1>
<p>Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.</p>
<p>Fortunately, there are tools that help with finding the best combination of parameters.
<a class="reference external" href="https://docs.ray.io/en/latest/tune.html">Ray Tune</a> is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through <a class="reference external" href="https://ray.io/">Ray’s distributed machine learning engine</a>.</p>
<p>In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">this tutorial from the PyTorch documentation</a> for training
a CIFAR10 image classifier.</p>
<p>As you will see, we only need to add some slight modifications. In particular, we
need to</p>
<ol class="arabic simple">
<li>wrap data loading and training in functions,</li>
<li>make some network parameters configurable,</li>
<li>add checkpointing (optional),</li>
<li>and define the search space for the model tuning</li>
</ol>
<div class="line-block">
<div class="line"><br/></div>
</div>
<p>To run this tutorial, please make sure the following packages are
installed:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">ray[tune]</span></code>: Distributed hyperparameter tuning library</li>
<li><code class="docutils literal notranslate"><span class="pre">torchvision</span></code>: For the data transformers</li>
</ul>
<div class="section" id="setup-imports">
<h2>Setup / Imports<a class="headerlink" href="#setup-imports" title="Permalink to this headline">¶</a></h2>
<p>Let’s start with the imports:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">tune</span>
<span class="kn">from</span> <span class="nn">ray.tune</span> <span class="kn">import</span> <span class="n">CLIReporter</span>
<span class="kn">from</span> <span class="nn">ray.tune.schedulers</span> <span class="kn">import</span> <span class="n">ASHAScheduler</span>
</pre></div>
</div>
<p>Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.</p>
</div>
<div class="section" id="data-loaders">
<h2>Data loaders<a class="headerlink" href="#data-loaders" title="Permalink to this headline">¶</a></h2>
<p>We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="o">=</span><span class="s2">"./data"</span><span class="p">):</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="p">])</span>

    <span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span>
</pre></div>
</div>
</div>
<div class="section" id="configurable-neural-network">
<h2>Configurable neural network<a class="headerlink" href="#configurable-neural-network" title="Permalink to this headline">¶</a></h2>
<p>We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l1</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mi">84</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="n">l1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<div class="section" id="the-train-function">
<h2>The train function<a class="headerlink" href="#the-train-function" title="Permalink to this headline">¶</a></h2>
<p>Now it gets interesting, because we introduce some changes to the example <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">from the PyTorch
documentation</a>.</p>
<p>We wrap the training script in a function <code class="docutils literal notranslate"><span class="pre">train_cifar(config,</span> <span class="pre">checkpoint_dir=None,</span> <span class="pre">data_dir=None)</span></code>.
As you can guess, the <code class="docutils literal notranslate"><span class="pre">config</span></code> parameter will receive the hyperparameters we would like to
train with. The <code class="docutils literal notranslate"><span class="pre">checkpoint_dir</span></code> parameter is used to restore checkpoints. The <code class="docutils literal notranslate"><span class="pre">data_dir</span></code> specifies
the directory where we load and store the data, so multiple runs can share the same data source.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

<span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>
</pre></div>
</div>
<p>The learning rate of the optimizer is made configurable, too:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<p>We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.</p>
<div class="section" id="adding-multi-gpu-support-with-dataparallel">
<h3>Adding (multi) GPU support with DataParallel<a class="headerlink" href="#adding-multi-gpu-support-with-dataparallel" title="Permalink to this headline">¶</a></h3>
<p>Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch’s abstractions in Ray Tune. Thus, we can wrap our model in <code class="docutils literal notranslate"><span class="pre">nn.DataParallel</span></code>
to support data parallel training on multiple GPUs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>By using a <code class="docutils literal notranslate"><span class="pre">device</span></code> variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports <a class="reference external" href="https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus">fractional GPUs</a>
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We’ll come back
to that later.</p>
</div>
<div class="section" id="communicating-with-ray-tune">
<h3>Communicating with Ray Tune<a class="headerlink" href="#communicating-with-ray-tune" title="Permalink to this headline">¶</a></h3>
<p>The most interesting part is the communication with Ray Tune:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

<span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.</p>
<p>The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
<a class="reference external" href="https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html">Population Based Training</a>.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.</p>
</div>
<div class="section" id="full-training-function">
<h3>Full training function<a class="headerlink" href="#full-training-function" title="Permalink to this headline">¶</a></h3>
<p>The full code example looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_cifar</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
        <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>

    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>

    <span class="n">test_abs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
    <span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
        <span class="n">trainset</span><span class="p">,</span> <span class="p">[</span><span class="n">test_abs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_abs</span><span class="p">])</span>

    <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">train_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">valloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">val_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">epoch_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># get the inputs; data is a list of [inputs, labels]</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># zero the parameter gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># forward + backward + optimize</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># print statistics</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">epoch_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2000</span> <span class="o">==</span> <span class="mi">1999</span><span class="p">:</span>  <span class="c1"># print every 2000 mini-batches</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"[</span><span class="si">%d</span><span class="s2">, </span><span class="si">%5d</span><span class="s2">] loss: </span><span class="si">%.3f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                <span class="n">running_loss</span> <span class="o">/</span> <span class="n">epoch_steps</span><span class="p">))</span>
                <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c1"># Validation loss</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">val_steps</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Finished Training"</span><span class="p">)</span>
</pre></div>
</div>
<p>As you can see, most of the code is adapted directly from the original example.</p>
</div>
</div>
<div class="section" id="test-set-accuracy">
<h2>Test set accuracy<a class="headerlink" href="#test-set-accuracy" title="Permalink to this headline">¶</a></h2>
<p>Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">):</span>
    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

    <span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</pre></div>
</div>
<p>The function also expects a <code class="docutils literal notranslate"><span class="pre">device</span></code> parameter, so we can do the
test set validation on a GPU.</p>
</div>
<div class="section" id="configuring-the-search-space">
<h2>Configuring the search space<a class="headerlink" href="#configuring-the-search-space" title="Permalink to this headline">¶</a></h2>
<p>Lastly, we need to define Ray Tune’s search space. Here is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">tune.sample_from()</span></code> function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the <code class="docutils literal notranslate"><span class="pre">l1</span></code> and <code class="docutils literal notranslate"><span class="pre">l2</span></code> parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The <code class="docutils literal notranslate"><span class="pre">lr</span></code> (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.</p>
<p>At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the <code class="docutils literal notranslate"><span class="pre">ASHAScheduler</span></code> which will terminate bad
performing trials early.</p>
<p>We wrap the <code class="docutils literal notranslate"><span class="pre">train_cifar</span></code> function with <code class="docutils literal notranslate"><span class="pre">functools.partial</span></code> to set the constant
<code class="docutils literal notranslate"><span class="pre">data_dir</span></code> parameter. We can also tell Ray Tune what resources should be
available for each trial:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gpus_per_trial</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># ...</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
    <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">,</span>
    <span class="n">checkpoint_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>You can specify the number of CPUs, which are then available e.g.
to increase the <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> of the PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven’t been requested for them - so you don’t have to care about two trials
using the same set of resources.</p>
<p>Here we can also specify fractional GPUs, so something like <code class="docutils literal notranslate"><span class="pre">gpus_per_trial=0.5</span></code> is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.</p>
<p>After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.</p>
<p>The full main function looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">"./data"</span><span class="p">)</span>
    <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
        <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
    <span class="p">}</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">ASHAScheduler</span><span class="p">(</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">"loss"</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">"min"</span><span class="p">,</span>
        <span class="n">max_t</span><span class="o">=</span><span class="n">max_num_epochs</span><span class="p">,</span>
        <span class="n">grace_period</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">reporter</span> <span class="o">=</span> <span class="n">CLIReporter</span><span class="p">(</span>
        <span class="c1"># parameter_columns=["l1", "l2", "lr", "batch_size"],</span>
        <span class="n">metric_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"training_iteration"</span><span class="p">])</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
        <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">)</span>

    <span class="n">best_trial</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">get_best_trial</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"min"</span><span class="p">,</span> <span class="s2">"last"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial config: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation loss: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">]))</span>

    <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">gpus_per_trial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">)</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">best_checkpoint_dir</span> <span class="o">=</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">value</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">best_checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>

    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_accuracy</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial test set accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="c1"># You can change the number of GPUs per trial here:</span>
    <span class="n">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
Files already downloaded and verified
== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (9 PENDING, 1 RUNNING)
+---------------------+----------+-------+--------------+------+------+-------------+
| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |
|---------------------+----------+-------+--------------+------+------+-------------|
| DEFAULT_3be5d_00000 | RUNNING  |       |            8 |    4 |   64 | 0.040451    |
| DEFAULT_3be5d_00001 | PENDING  |       |            2 |   16 |   64 | 0.081644    |
| DEFAULT_3be5d_00002 | PENDING  |       |           16 |   64 |  256 | 0.0338347   |
| DEFAULT_3be5d_00003 | PENDING  |       |            4 |   16 |  256 | 0.0534941   |
| DEFAULT_3be5d_00004 | PENDING  |       |            8 |    4 |    4 | 0.000265259 |
| DEFAULT_3be5d_00005 | PENDING  |       |            2 |   64 |   64 | 0.000253839 |
| DEFAULT_3be5d_00006 | PENDING  |       |            2 |    8 |    8 | 0.000870384 |
| DEFAULT_3be5d_00007 | PENDING  |       |            2 |  128 |   32 | 0.00471899  |
| DEFAULT_3be5d_00008 | PENDING  |       |            4 |   16 |  256 | 0.0263969   |
| DEFAULT_3be5d_00009 | PENDING  |       |            8 |   32 |  256 | 0.00178228  |
+---------------------+----------+-------+--------------+------+------+-------------+


[2m[36m(pid=1173)[0m Files already downloaded and verified
[2m[36m(pid=1084)[0m Files already downloaded and verified
[2m[36m(pid=1091)[0m Files already downloaded and verified
[2m[36m(pid=1168)[0m Files already downloaded and verified
[2m[36m(pid=1102)[0m Files already downloaded and verified
[2m[36m(pid=1110)[0m Files already downloaded and verified
[2m[36m(pid=1142)[0m Files already downloaded and verified
[2m[36m(pid=1088)[0m Files already downloaded and verified
[2m[36m(pid=1085)[0m Files already downloaded and verified
[2m[36m(pid=1087)[0m Files already downloaded and verified
[2m[36m(pid=1173)[0m Files already downloaded and verified
[2m[36m(pid=1084)[0m Files already downloaded and verified
[2m[36m(pid=1168)[0m Files already downloaded and verified
[2m[36m(pid=1102)[0m Files already downloaded and verified
[2m[36m(pid=1110)[0m Files already downloaded and verified
[2m[36m(pid=1142)[0m Files already downloaded and verified
[2m[36m(pid=1091)[0m Files already downloaded and verified
[2m[36m(pid=1088)[0m Files already downloaded and verified
[2m[36m(pid=1085)[0m Files already downloaded and verified
[2m[36m(pid=1087)[0m Files already downloaded and verified
[2m[36m(pid=1168)[0m [1,  2000] loss: 2.303
[2m[36m(pid=1085)[0m [1,  2000] loss: 2.397
[2m[36m(pid=1102)[0m [1,  2000] loss: 2.303
[2m[36m(pid=1110)[0m [1,  2000] loss: 2.178
[2m[36m(pid=1091)[0m [1,  2000] loss: 2.331
[2m[36m(pid=1088)[0m [1,  2000] loss: 2.321
[2m[36m(pid=1173)[0m [1,  2000] loss: 2.315
[2m[36m(pid=1142)[0m [1,  2000] loss: 2.320
[2m[36m(pid=1084)[0m [1,  2000] loss: 2.058
[2m[36m(pid=1087)[0m [1,  2000] loss: 1.965
[2m[36m(pid=1168)[0m [1,  4000] loss: 1.150
[2m[36m(pid=1102)[0m [1,  4000] loss: 1.094
[2m[36m(pid=1085)[0m [1,  4000] loss: 1.196
[2m[36m(pid=1110)[0m [1,  4000] loss: 1.010
[2m[36m(pid=1091)[0m [1,  4000] loss: 1.166
[2m[36m(pid=1088)[0m [1,  4000] loss: 1.154
Result for DEFAULT_3be5d_00002:
  accuracy: 0.2831
  date: 2020-10-02_16-14-10
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 1.9551224758148193
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 29.5739803314209
  time_this_iter_s: 29.5739803314209
  time_total_s: 29.5739803314209
  timestamp: 1601655250
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 8.8/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.9551224758148193
Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (10 RUNNING)
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | RUNNING  |                 |            8 |    4 |   64 | 0.040451    |         |            |                      |
| DEFAULT_3be5d_00001 | RUNNING  |                 |            2 |   16 |   64 | 0.081644    |         |            |                      |
| DEFAULT_3be5d_00002 | RUNNING  | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.95512 |     0.2831 |                    1 |
| DEFAULT_3be5d_00003 | RUNNING  |                 |            4 |   16 |  256 | 0.0534941   |         |            |                      |
| DEFAULT_3be5d_00004 | RUNNING  |                 |            8 |    4 |    4 | 0.000265259 |         |            |                      |
| DEFAULT_3be5d_00005 | RUNNING  |                 |            2 |   64 |   64 | 0.000253839 |         |            |                      |
| DEFAULT_3be5d_00006 | RUNNING  |                 |            2 |    8 |    8 | 0.000870384 |         |            |                      |
| DEFAULT_3be5d_00007 | RUNNING  |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | RUNNING  |                 |            4 |   16 |  256 | 0.0263969   |         |            |                      |
| DEFAULT_3be5d_00009 | RUNNING  |                 |            8 |   32 |  256 | 0.00178228  |         |            |                      |
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1173)[0m [1,  4000] loss: 1.157
[2m[36m(pid=1142)[0m [1,  4000] loss: 1.153
[2m[36m(pid=1084)[0m [1,  4000] loss: 0.831
[2m[36m(pid=1168)[0m [1,  6000] loss: 0.762
[2m[36m(pid=1102)[0m [1,  6000] loss: 0.669
[2m[36m(pid=1085)[0m [1,  6000] loss: 0.799
[2m[36m(pid=1110)[0m [1,  6000] loss: 0.647
[2m[36m(pid=1091)[0m [1,  6000] loss: 0.778
[2m[36m(pid=1088)[0m [1,  6000] loss: 0.772
Result for DEFAULT_3be5d_00004:
  accuracy: 0.1021
  date: 2020-10-02_16-14-23
  done: true
  experiment_id: 59295a792d2249dc962b7964397ee817
  experiment_tag: 4_batch_size=8,l1=4,l2=4,lr=0.00026526
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 2.295366014480591
  node_ip: 172.17.0.2
  pid: 1142
  should_checkpoint: true
  time_since_restore: 42.19787406921387
  time_this_iter_s: 42.19787406921387
  time_total_s: 42.19787406921387
  timestamp: 1601655263
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00004

== Status ==
Memory usage on this node: 8.8/240.1 GiB
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.125244245147705
Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (10 RUNNING)
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | RUNNING  |                 |            8 |    4 |   64 | 0.040451    |         |            |                      |
| DEFAULT_3be5d_00001 | RUNNING  |                 |            2 |   16 |   64 | 0.081644    |         |            |                      |
| DEFAULT_3be5d_00002 | RUNNING  | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.95512 |     0.2831 |                    1 |
| DEFAULT_3be5d_00003 | RUNNING  |                 |            4 |   16 |  256 | 0.0534941   |         |            |                      |
| DEFAULT_3be5d_00004 | RUNNING  | 172.17.0.2:1142 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING  |                 |            2 |   64 |   64 | 0.000253839 |         |            |                      |
| DEFAULT_3be5d_00006 | RUNNING  |                 |            2 |    8 |    8 | 0.000870384 |         |            |                      |
| DEFAULT_3be5d_00007 | RUNNING  |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | RUNNING  |                 |            4 |   16 |  256 | 0.0263969   |         |            |                      |
| DEFAULT_3be5d_00009 | RUNNING  |                 |            8 |   32 |  256 | 0.00178228  |         |            |                      |
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_3be5d_00000:
  accuracy: 0.0995
  date: 2020-10-02_16-14-23
  done: true
  experiment_id: 55988d4cbd7646fdb6e07ba8ef8c48c1
  experiment_tag: 0_batch_size=8,l1=4,l2=64,lr=0.040451
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 2.320113194656372
  node_ip: 172.17.0.2
  pid: 1173
  should_checkpoint: true
  time_since_restore: 42.429874897003174
  time_this_iter_s: 42.429874897003174
  time_total_s: 42.429874897003174
  timestamp: 1601655263
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00000

Result for DEFAULT_3be5d_00009:
  accuracy: 0.4368
  date: 2020-10-02_16-14-23
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 1.4943109789371491
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 42.9139289855957
  time_this_iter_s: 42.9139289855957
  time_total_s: 42.9139289855957
  timestamp: 1601655263
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00009

[2m[36m(pid=1087)[0m [2,  2000] loss: 1.895
[2m[36m(pid=1168)[0m [1,  8000] loss: 0.533
[2m[36m(pid=1102)[0m [1,  8000] loss: 0.474
[2m[36m(pid=1085)[0m [1,  8000] loss: 0.601
[2m[36m(pid=1110)[0m [1,  8000] loss: 0.487
[2m[36m(pid=1091)[0m [1,  8000] loss: 0.583
[2m[36m(pid=1088)[0m [1,  8000] loss: 0.580
Result for DEFAULT_3be5d_00002:
  accuracy: 0.3192
  date: 2020-10-02_16-14-32
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 2
  loss: 1.8690864231109618
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 51.51978397369385
  time_this_iter_s: 21.94580364227295
  time_total_s: 51.51978397369385
  timestamp: 1601655272
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 7.8/240.1 GiB
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8690864231109618 | Iter 1.000: -2.125244245147705
Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (8 RUNNING, 2 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | RUNNING    |                 |            2 |   16 |   64 | 0.081644    |         |            |                      |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.86909 |     0.3192 |                    2 |
| DEFAULT_3be5d_00003 | RUNNING    |                 |            4 |   16 |  256 | 0.0534941   |         |            |                      |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    |                 |            2 |   64 |   64 | 0.000253839 |         |            |                      |
| DEFAULT_3be5d_00006 | RUNNING    |                 |            2 |    8 |    8 | 0.000870384 |         |            |                      |
| DEFAULT_3be5d_00007 | RUNNING    |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | RUNNING    |                 |            4 |   16 |  256 | 0.0263969   |         |            |                      |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.49431 |     0.4368 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1084)[0m [2,  2000] loss: 1.451
[2m[36m(pid=1168)[0m [1, 10000] loss: 0.388
[2m[36m(pid=1102)[0m [1, 10000] loss: 0.361
[2m[36m(pid=1085)[0m [1, 10000] loss: 0.479
[2m[36m(pid=1110)[0m [1, 10000] loss: 0.389
[2m[36m(pid=1091)[0m [1, 10000] loss: 0.467
[2m[36m(pid=1088)[0m [1, 10000] loss: 0.463
[2m[36m(pid=1168)[0m [1, 12000] loss: 0.306
[2m[36m(pid=1102)[0m [1, 12000] loss: 0.296
[2m[36m(pid=1085)[0m [1, 12000] loss: 0.400
[2m[36m(pid=1084)[0m [2,  4000] loss: 0.685
[2m[36m(pid=1087)[0m [3,  2000] loss: 1.914
Result for DEFAULT_3be5d_00003:
  accuracy: 0.1001
  date: 2020-10-02_16-14-47
  done: true
  experiment_id: 74acacd345d54e0ca0e2ca2812e054b9
  experiment_tag: 3_batch_size=4,l1=16,l2=256,lr=0.053494
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 2.328571516036987
  node_ip: 172.17.0.2
  pid: 1091
  should_checkpoint: true
  time_since_restore: 66.73637700080872
  time_this_iter_s: 66.73637700080872
  time_total_s: 66.73637700080872
  timestamp: 1601655287
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00003

== Status ==
Memory usage on this node: 7.8/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8690864231109618 | Iter 1.000: -2.295366014480591
Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (8 RUNNING, 2 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | RUNNING    |                 |            2 |   16 |   64 | 0.081644    |         |            |                      |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.86909 |     0.3192 |                    2 |
| DEFAULT_3be5d_00003 | RUNNING    | 172.17.0.2:1091 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    |                 |            2 |   64 |   64 | 0.000253839 |         |            |                      |
| DEFAULT_3be5d_00006 | RUNNING    |                 |            2 |    8 |    8 | 0.000870384 |         |            |                      |
| DEFAULT_3be5d_00007 | RUNNING    |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | RUNNING    |                 |            4 |   16 |  256 | 0.0263969   |         |            |                      |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.49431 |     0.4368 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_3be5d_00008:
  accuracy: 0.0994
  date: 2020-10-02_16-14-48
  done: true
  experiment_id: afc4eaf05ab9433ea587fd888eca4918
  experiment_tag: 8_batch_size=4,l1=16,l2=256,lr=0.026397
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 2.312486482715607
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 67.17249321937561
  time_this_iter_s: 67.17249321937561
  time_total_s: 67.17249321937561
  timestamp: 1601655288
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00008

[2m[36m(pid=1110)[0m [1, 12000] loss: 0.325
[2m[36m(pid=1168)[0m [1, 14000] loss: 0.255
[2m[36m(pid=1102)[0m [1, 14000] loss: 0.248
Result for DEFAULT_3be5d_00002:
  accuracy: 0.2796
  date: 2020-10-02_16-14-53
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 3
  loss: 1.9110948236465455
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 72.32724356651306
  time_this_iter_s: 20.807459592819214
  time_total_s: 72.32724356651306
  timestamp: 1601655293
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 6.7/240.1 GiB
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8690864231109618 | Iter 1.000: -2.303926248598099
Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (6 RUNNING, 4 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | RUNNING    |                 |            2 |   16 |   64 | 0.081644    |         |            |                      |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.91109 |     0.2796 |                    3 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    |                 |            2 |   64 |   64 | 0.000253839 |         |            |                      |
| DEFAULT_3be5d_00006 | RUNNING    |                 |            2 |    8 |    8 | 0.000870384 |         |            |                      |
| DEFAULT_3be5d_00007 | RUNNING    |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.49431 |     0.4368 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1085)[0m [1, 14000] loss: 0.342
Result for DEFAULT_3be5d_00009:
  accuracy: 0.4987
  date: 2020-10-02_16-14-55
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 2
  loss: 1.361898309469223
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 74.85919117927551
  time_this_iter_s: 31.94526219367981
  time_total_s: 74.85919117927551
  timestamp: 1601655295
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 3be5d_00009

[2m[36m(pid=1110)[0m [1, 14000] loss: 0.278
[2m[36m(pid=1102)[0m [1, 16000] loss: 0.215
[2m[36m(pid=1168)[0m [1, 16000] loss: 0.217
[2m[36m(pid=1085)[0m [1, 16000] loss: 0.300
[2m[36m(pid=1110)[0m [1, 16000] loss: 0.245
[2m[36m(pid=1084)[0m [3,  2000] loss: 1.268
[2m[36m(pid=1087)[0m [4,  2000] loss: 1.915
[2m[36m(pid=1102)[0m [1, 18000] loss: 0.183
[2m[36m(pid=1168)[0m [1, 18000] loss: 0.189
[2m[36m(pid=1085)[0m [1, 18000] loss: 0.266
Result for DEFAULT_3be5d_00002:
  accuracy: 0.2652
  date: 2020-10-02_16-15-13
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 4
  loss: 1.9224515295028686
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 92.559410572052
  time_this_iter_s: 20.23216700553894
  time_total_s: 92.559410572052
  timestamp: 1601655313
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 6.7/240.1 GiB
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.9224515295028686 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.303926248598099
Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (6 RUNNING, 4 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | RUNNING    |                 |            2 |   16 |   64 | 0.081644    |         |            |                      |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.92245 |     0.2652 |                    4 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    |                 |            2 |   64 |   64 | 0.000253839 |         |            |                      |
| DEFAULT_3be5d_00006 | RUNNING    |                 |            2 |    8 |    8 | 0.000870384 |         |            |                      |
| DEFAULT_3be5d_00007 | RUNNING    |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.3619  |     0.4987 |                    2 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1110)[0m [1, 18000] loss: 0.214
[2m[36m(pid=1102)[0m [1, 20000] loss: 0.162
[2m[36m(pid=1084)[0m [3,  4000] loss: 0.627
[2m[36m(pid=1168)[0m [1, 20000] loss: 0.164
[2m[36m(pid=1085)[0m [1, 20000] loss: 0.239
[2m[36m(pid=1110)[0m [1, 20000] loss: 0.193
Result for DEFAULT_3be5d_00009:
  accuracy: 0.5612
  date: 2020-10-02_16-15-26
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 3
  loss: 1.2375875360012054
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 105.88276243209839
  time_this_iter_s: 31.023571252822876
  time_total_s: 105.88276243209839
  timestamp: 1601655326
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 3be5d_00009

== Status ==
Memory usage on this node: 6.7/240.1 GiB
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -1.9224515295028686 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.303926248598099
Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (6 RUNNING, 4 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | RUNNING    |                 |            2 |   16 |   64 | 0.081644    |         |            |                      |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.92245 |     0.2652 |                    4 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    |                 |            2 |   64 |   64 | 0.000253839 |         |            |                      |
| DEFAULT_3be5d_00006 | RUNNING    |                 |            2 |    8 |    8 | 0.000870384 |         |            |                      |
| DEFAULT_3be5d_00007 | RUNNING    |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.23759 |     0.5612 |                    3 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1087)[0m [5,  2000] loss: 1.911
Result for DEFAULT_3be5d_00006:
  accuracy: 0.3978
  date: 2020-10-02_16-15-29
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 1.6176750984340906
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 108.56034064292908
  time_this_iter_s: 108.56034064292908
  time_total_s: 108.56034064292908
  timestamp: 1601655329
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00006

Result for DEFAULT_3be5d_00005:
  accuracy: 0.3961
  date: 2020-10-02_16-15-30
  done: false
  experiment_id: c68de2ef6dd4450d837db65449b25ef2
  experiment_tag: 5_batch_size=2,l1=64,l2=64,lr=0.00025384
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 1.6327883035004138
  node_ip: 172.17.0.2
  pid: 1168
  should_checkpoint: true
  time_since_restore: 109.28108477592468
  time_this_iter_s: 109.28108477592468
  time_total_s: 109.28108477592468
  timestamp: 1601655330
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00005

Result for DEFAULT_3be5d_00001:
  accuracy: 0.1036
  date: 2020-10-02_16-15-32
  done: true
  experiment_id: ea0a170b7c2f4cb3a54f18897e10a2b8
  experiment_tag: 1_batch_size=2,l1=16,l2=64,lr=0.081644
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 2.4751316098928453
  node_ip: 172.17.0.2
  pid: 1085
  should_checkpoint: true
  time_since_restore: 111.51632285118103
  time_this_iter_s: 111.51632285118103
  time_total_s: 111.51632285118103
  timestamp: 1601655332
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00001

== Status ==
Memory usage on this node: 6.7/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9224515295028686 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.295366014480591
Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (6 RUNNING, 4 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | RUNNING    | 172.17.0.2:1085 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.92245 |     0.2652 |                    4 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    | 172.17.0.2:1168 |            2 |   64 |   64 | 0.000253839 | 1.63279 |     0.3961 |                    1 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.61768 |     0.3978 |                    1 |
| DEFAULT_3be5d_00007 | RUNNING    |                 |            2 |  128 |   32 | 0.00471899  |         |            |                      |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.23759 |     0.5612 |                    3 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_3be5d_00002:
  accuracy: 0.2616
  date: 2020-10-02_16-15-34
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 5
  loss: 1.932469069671631
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 113.19421219825745
  time_this_iter_s: 20.634801626205444
  time_total_s: 113.19421219825745
  timestamp: 1601655334
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 3be5d_00002

Result for DEFAULT_3be5d_00007:
  accuracy: 0.2676
  date: 2020-10-02_16-15-36
  done: false
  experiment_id: e8d9f9b32b544c5695c8979f703728e0
  experiment_tag: 7_batch_size=2,l1=128,l2=32,lr=0.004719
  hostname: db608dfe860a
  iterations_since_restore: 1
  loss: 1.974265598345548
  node_ip: 172.17.0.2
  pid: 1110
  should_checkpoint: true
  time_since_restore: 115.1789448261261
  time_this_iter_s: 115.1789448261261
  time_total_s: 115.1789448261261
  timestamp: 1601655336
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 3be5d_00007

[2m[36m(pid=1084)[0m [4,  2000] loss: 1.183
[2m[36m(pid=1102)[0m [2,  2000] loss: 1.587
[2m[36m(pid=1168)[0m [2,  2000] loss: 1.625
[2m[36m(pid=1110)[0m [2,  2000] loss: 1.942
[2m[36m(pid=1102)[0m [2,  4000] loss: 0.787
[2m[36m(pid=1168)[0m [2,  4000] loss: 0.792
[2m[36m(pid=1084)[0m [4,  4000] loss: 0.591
[2m[36m(pid=1087)[0m [6,  2000] loss: 1.919
[2m[36m(pid=1102)[0m [2,  6000] loss: 0.509
[2m[36m(pid=1110)[0m [2,  4000] loss: 0.968
Result for DEFAULT_3be5d_00002:
  accuracy: 0.2816
  date: 2020-10-02_16-15-54
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 6
  loss: 1.9271182090759278
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 132.99067616462708
  time_this_iter_s: 19.79646396636963
  time_total_s: 132.99067616462708
  timestamp: 1601655354
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9224515295028686 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.1348158064130693
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.92712 |     0.2816 |                    6 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    | 172.17.0.2:1168 |            2 |   64 |   64 | 0.000253839 | 1.63279 |     0.3961 |                    1 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.61768 |     0.3978 |                    1 |
| DEFAULT_3be5d_00007 | RUNNING    | 172.17.0.2:1110 |            2 |  128 |   32 | 0.00471899  | 1.97427 |     0.2676 |                    1 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.23759 |     0.5612 |                    3 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1168)[0m [2,  6000] loss: 0.523
Result for DEFAULT_3be5d_00009:
  accuracy: 0.5697
  date: 2020-10-02_16-15-57
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 4
  loss: 1.2248023574113847
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 136.25503420829773
  time_this_iter_s: 30.37227177619934
  time_total_s: 136.25503420829773
  timestamp: 1601655357
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 3be5d_00009

[2m[36m(pid=1102)[0m [2,  8000] loss: 0.385
[2m[36m(pid=1110)[0m [2,  6000] loss: 0.640
[2m[36m(pid=1168)[0m [2,  8000] loss: 0.387
[2m[36m(pid=1084)[0m [5,  2000] loss: 1.123
[2m[36m(pid=1087)[0m [7,  2000] loss: 1.921
[2m[36m(pid=1102)[0m [2, 10000] loss: 0.301
[2m[36m(pid=1168)[0m [2, 10000] loss: 0.307
[2m[36m(pid=1110)[0m [2,  8000] loss: 0.491
Result for DEFAULT_3be5d_00002:
  accuracy: 0.2889
  date: 2020-10-02_16-16-14
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 7
  loss: 1.921483536338806
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 152.97952961921692
  time_this_iter_s: 19.988853454589844
  time_total_s: 152.97952961921692
  timestamp: 1601655374
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.1348158064130693
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.92148 |     0.2889 |                    7 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    | 172.17.0.2:1168 |            2 |   64 |   64 | 0.000253839 | 1.63279 |     0.3961 |                    1 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.61768 |     0.3978 |                    1 |
| DEFAULT_3be5d_00007 | RUNNING    | 172.17.0.2:1110 |            2 |  128 |   32 | 0.00471899  | 1.97427 |     0.2676 |                    1 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.2248  |     0.5697 |                    4 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [2, 12000] loss: 0.251
[2m[36m(pid=1084)[0m [5,  4000] loss: 0.563
[2m[36m(pid=1168)[0m [2, 12000] loss: 0.248
[2m[36m(pid=1110)[0m [2, 10000] loss: 0.390
[2m[36m(pid=1102)[0m [2, 14000] loss: 0.215
[2m[36m(pid=1168)[0m [2, 14000] loss: 0.214
Result for DEFAULT_3be5d_00009:
  accuracy: 0.5805
  date: 2020-10-02_16-16-27
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 5
  loss: 1.1735660487294197
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 166.37924075126648
  time_this_iter_s: 30.12420654296875
  time_total_s: 166.37924075126648
  timestamp: 1601655387
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 3be5d_00009

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.1348158064130693
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.92148 |     0.2889 |                    7 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    | 172.17.0.2:1168 |            2 |   64 |   64 | 0.000253839 | 1.63279 |     0.3961 |                    1 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.61768 |     0.3978 |                    1 |
| DEFAULT_3be5d_00007 | RUNNING    | 172.17.0.2:1110 |            2 |  128 |   32 | 0.00471899  | 1.97427 |     0.2676 |                    1 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.17357 |     0.5805 |                    5 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1087)[0m [8,  2000] loss: 1.937
[2m[36m(pid=1110)[0m [2, 12000] loss: 0.331
[2m[36m(pid=1102)[0m [2, 16000] loss: 0.188
Result for DEFAULT_3be5d_00002:
  accuracy: 0.2825
  date: 2020-10-02_16-16-34
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 8
  loss: 1.9194766944885253
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 173.09670996665955
  time_this_iter_s: 20.117180347442627
  time_total_s: 173.09670996665955
  timestamp: 1601655394
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -1.9194766944885253 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.1348158064130693
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.91948 |     0.2825 |                    8 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    | 172.17.0.2:1168 |            2 |   64 |   64 | 0.000253839 | 1.63279 |     0.3961 |                    1 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.61768 |     0.3978 |                    1 |
| DEFAULT_3be5d_00007 | RUNNING    | 172.17.0.2:1110 |            2 |  128 |   32 | 0.00471899  | 1.97427 |     0.2676 |                    1 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.17357 |     0.5805 |                    5 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1168)[0m [2, 16000] loss: 0.187
[2m[36m(pid=1110)[0m [2, 14000] loss: 0.275
[2m[36m(pid=1084)[0m [6,  2000] loss: 1.077
[2m[36m(pid=1102)[0m [2, 18000] loss: 0.166
[2m[36m(pid=1168)[0m [2, 18000] loss: 0.159
[2m[36m(pid=1110)[0m [2, 16000] loss: 0.244
[2m[36m(pid=1087)[0m [9,  2000] loss: 1.935
[2m[36m(pid=1084)[0m [6,  4000] loss: 0.550
[2m[36m(pid=1102)[0m [2, 20000] loss: 0.150
[2m[36m(pid=1168)[0m [2, 20000] loss: 0.141
Result for DEFAULT_3be5d_00002:
  accuracy: 0.255
  date: 2020-10-02_16-16-54
  done: false
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 9
  loss: 1.9736097717285157
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 193.08217763900757
  time_this_iter_s: 19.985467672348022
  time_total_s: 193.08217763900757
  timestamp: 1601655414
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -1.9194766944885253 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.6154923662900924 | Iter 1.000: -2.1348158064130693
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.97361 |     0.255  |                    9 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    | 172.17.0.2:1168 |            2 |   64 |   64 | 0.000253839 | 1.63279 |     0.3961 |                    1 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.61768 |     0.3978 |                    1 |
| DEFAULT_3be5d_00007 | RUNNING    | 172.17.0.2:1110 |            2 |  128 |   32 | 0.00471899  | 1.97427 |     0.2676 |                    1 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.17357 |     0.5805 |                    5 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1110)[0m [2, 18000] loss: 0.219
Result for DEFAULT_3be5d_00009:
  accuracy: 0.55
  date: 2020-10-02_16-16-57
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 6
  loss: 1.2611771823644637
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 196.55099415779114
  time_this_iter_s: 30.171753406524658
  time_total_s: 196.55099415779114
  timestamp: 1601655417
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 3be5d_00009

Result for DEFAULT_3be5d_00006:
  accuracy: 0.4606
  date: 2020-10-02_16-17-01
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 2
  loss: 1.4595317358970643
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 200.07978916168213
  time_this_iter_s: 91.51944851875305
  time_total_s: 200.07978916168213
  timestamp: 1601655421
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -1.9194766944885253 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.4595317358970643 | Iter 1.000: -2.1348158064130693
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.97361 |     0.255  |                    9 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | RUNNING    | 172.17.0.2:1168 |            2 |   64 |   64 | 0.000253839 | 1.63279 |     0.3961 |                    1 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.45953 |     0.4606 |                    2 |
| DEFAULT_3be5d_00007 | RUNNING    | 172.17.0.2:1110 |            2 |  128 |   32 | 0.00471899  | 1.97427 |     0.2676 |                    1 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.26118 |     0.55   |                    6 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_3be5d_00005:
  accuracy: 0.4613
  date: 2020-10-02_16-17-03
  done: true
  experiment_id: c68de2ef6dd4450d837db65449b25ef2
  experiment_tag: 5_batch_size=2,l1=64,l2=64,lr=0.00025384
  hostname: db608dfe860a
  iterations_since_restore: 2
  loss: 1.4978141681149602
  node_ip: 172.17.0.2
  pid: 1168
  should_checkpoint: true
  time_since_restore: 202.708176612854
  time_this_iter_s: 93.42709183692932
  time_total_s: 202.708176612854
  timestamp: 1601655423
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 3be5d_00005

[2m[36m(pid=1110)[0m [2, 20000] loss: 0.198
[2m[36m(pid=1084)[0m [7,  2000] loss: 1.029
[2m[36m(pid=1087)[0m [10,  2000] loss: 1.928
[2m[36m(pid=1102)[0m [3,  2000] loss: 1.437
Result for DEFAULT_3be5d_00002:
  accuracy: 0.2371
  date: 2020-10-02_16-17-14
  done: true
  experiment_id: 806521689d96490c8407ccb9e6bf58ca
  experiment_tag: 2_batch_size=16,l1=64,l2=256,lr=0.033835
  hostname: db608dfe860a
  iterations_since_restore: 10
  loss: 1.9534709293365478
  node_ip: 172.17.0.2
  pid: 1087
  should_checkpoint: true
  time_since_restore: 213.01450729370117
  time_this_iter_s: 19.932329654693604
  time_total_s: 213.01450729370117
  timestamp: 1601655434
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 3be5d_00002

== Status ==
Memory usage on this node: 5.7/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.9194766944885253 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.4786729520060122 | Iter 1.000: -2.1348158064130693
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | RUNNING    | 172.17.0.2:1087 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.45953 |     0.4606 |                    2 |
| DEFAULT_3be5d_00007 | RUNNING    | 172.17.0.2:1110 |            2 |  128 |   32 | 0.00471899  | 1.97427 |     0.2676 |                    1 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.26118 |     0.55   |                    6 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_3be5d_00007:
  accuracy: 0.2501
  date: 2020-10-02_16-17-16
  done: true
  experiment_id: e8d9f9b32b544c5695c8979f703728e0
  experiment_tag: 7_batch_size=2,l1=128,l2=32,lr=0.004719
  hostname: db608dfe860a
  iterations_since_restore: 2
  loss: 1.9570300538986922
  node_ip: 172.17.0.2
  pid: 1110
  should_checkpoint: true
  time_since_restore: 215.27274560928345
  time_this_iter_s: 100.09380078315735
  time_total_s: 215.27274560928345
  timestamp: 1601655436
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 3be5d_00007

[2m[36m(pid=1102)[0m [3,  4000] loss: 0.742
[2m[36m(pid=1084)[0m [7,  4000] loss: 0.536
[2m[36m(pid=1102)[0m [3,  6000] loss: 0.473
Result for DEFAULT_3be5d_00009:
  accuracy: 0.5869
  date: 2020-10-02_16-17-26
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 7
  loss: 1.1758272482991219
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 225.45907878875732
  time_this_iter_s: 28.908084630966187
  time_total_s: 225.45907878875732
  timestamp: 1601655446
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 3be5d_00009

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.9194766944885253 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.45953 |     0.4606 |                    2 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.17583 |     0.5869 |                    7 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [3,  8000] loss: 0.356
[2m[36m(pid=1084)[0m [8,  2000] loss: 1.014
[2m[36m(pid=1102)[0m [3, 10000] loss: 0.288
[2m[36m(pid=1102)[0m [3, 12000] loss: 0.238
[2m[36m(pid=1084)[0m [8,  4000] loss: 0.518
[2m[36m(pid=1102)[0m [3, 14000] loss: 0.199
Result for DEFAULT_3be5d_00009:
  accuracy: 0.5848
  date: 2020-10-02_16-17-54
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 8
  loss: 1.200622837138176
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 253.98396062850952
  time_this_iter_s: 28.524881839752197
  time_total_s: 253.98396062850952
  timestamp: 1601655474
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 3be5d_00009

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.5600497658133508 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.45953 |     0.4606 |                    2 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.20062 |     0.5848 |                    8 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [3, 16000] loss: 0.177
[2m[36m(pid=1084)[0m [9,  2000] loss: 0.989
[2m[36m(pid=1102)[0m [3, 18000] loss: 0.157
[2m[36m(pid=1084)[0m [9,  4000] loss: 0.508
[2m[36m(pid=1102)[0m [3, 20000] loss: 0.141
Result for DEFAULT_3be5d_00009:
  accuracy: 0.5865
  date: 2020-10-02_16-18-23
  done: false
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 9
  loss: 1.1997563168644905
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 282.5412118434906
  time_this_iter_s: 28.55725121498108
  time_total_s: 282.5412118434906
  timestamp: 1601655503
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 3be5d_00009

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.5600497658133508 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.45953 |     0.4606 |                    2 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.19976 |     0.5865 |                    9 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_3be5d_00006:
  accuracy: 0.4869
  date: 2020-10-02_16-18-26
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 3
  loss: 1.4149299792299048
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 285.74832463264465
  time_this_iter_s: 85.66853547096252
  time_total_s: 285.74832463264465
  timestamp: 1601655506
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 3be5d_00006

[2m[36m(pid=1084)[0m [10,  2000] loss: 0.965
[2m[36m(pid=1102)[0m [4,  2000] loss: 1.364
[2m[36m(pid=1102)[0m [4,  4000] loss: 0.686
[2m[36m(pid=1084)[0m [10,  4000] loss: 0.498
[2m[36m(pid=1102)[0m [4,  6000] loss: 0.458
Result for DEFAULT_3be5d_00009:
  accuracy: 0.5738
  date: 2020-10-02_16-18-51
  done: true
  experiment_id: a15972af351f43ca886c8b648cbfa951
  experiment_tag: 9_batch_size=8,l1=32,l2=256,lr=0.0017823
  hostname: db608dfe860a
  iterations_since_restore: 10
  loss: 1.2235519858837127
  node_ip: 172.17.0.2
  pid: 1084
  should_checkpoint: true
  time_since_restore: 310.9136667251587
  time_this_iter_s: 28.37245488166809
  time_total_s: 310.9136667251587
  timestamp: 1601655531
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 3be5d_00009

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5600497658133508 | Iter 4.000: -1.5736269434571266 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.41493 |     0.4869 |                    3 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | RUNNING    | 172.17.0.2:1084 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [4,  8000] loss: 0.343
[2m[36m(pid=1102)[0m [4, 10000] loss: 0.279
[2m[36m(pid=1102)[0m [4, 12000] loss: 0.232
[2m[36m(pid=1102)[0m [4, 14000] loss: 0.193
[2m[36m(pid=1102)[0m [4, 16000] loss: 0.173
[2m[36m(pid=1102)[0m [4, 18000] loss: 0.149
[2m[36m(pid=1102)[0m [4, 20000] loss: 0.136
Result for DEFAULT_3be5d_00006:
  accuracy: 0.4972
  date: 2020-10-02_16-19-50
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 4
  loss: 1.3845566206591204
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 369.0389606952667
  time_this_iter_s: 83.29063606262207
  time_total_s: 369.0389606952667
  timestamp: 1601655590
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5600497658133508 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.38456 |     0.4972 |                    4 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |                 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [5,  2000] loss: 1.321
[2m[36m(pid=1102)[0m [5,  4000] loss: 0.685
[2m[36m(pid=1102)[0m [5,  6000] loss: 0.443
[2m[36m(pid=1102)[0m [5,  8000] loss: 0.335
[2m[36m(pid=1102)[0m [5, 10000] loss: 0.265
[2m[36m(pid=1102)[0m [5, 12000] loss: 0.220
[2m[36m(pid=1102)[0m [5, 14000] loss: 0.193
[2m[36m(pid=1102)[0m [5, 16000] loss: 0.168
[2m[36m(pid=1102)[0m [5, 18000] loss: 0.149
[2m[36m(pid=1102)[0m [5, 20000] loss: 0.131
Result for DEFAULT_3be5d_00006:
  accuracy: 0.5288
  date: 2020-10-02_16-21-13
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 5
  loss: 1.3154332349503413
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 452.15165877342224
  time_this_iter_s: 83.11269807815552
  time_total_s: 452.15165877342224
  timestamp: 1601655673
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5600497658133508 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.31543 |     0.5288 |                    5 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |                 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [6,  2000] loss: 1.297
[2m[36m(pid=1102)[0m [6,  4000] loss: 0.665
[2m[36m(pid=1102)[0m [6,  6000] loss: 0.432
[2m[36m(pid=1102)[0m [6,  8000] loss: 0.333
[2m[36m(pid=1102)[0m [6, 10000] loss: 0.262
[2m[36m(pid=1102)[0m [6, 12000] loss: 0.219
[2m[36m(pid=1102)[0m [6, 14000] loss: 0.187
[2m[36m(pid=1102)[0m [6, 16000] loss: 0.167
[2m[36m(pid=1102)[0m [6, 18000] loss: 0.147
[2m[36m(pid=1102)[0m [6, 20000] loss: 0.131
Result for DEFAULT_3be5d_00006:
  accuracy: 0.5192
  date: 2020-10-02_16-22-36
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 6
  loss: 1.3425580171143636
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 535.5244345664978
  time_this_iter_s: 83.37277579307556
  time_total_s: 535.5244345664978
  timestamp: 1601655756
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5600497658133508 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.34256 |     0.5192 |                    6 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |                 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [7,  2000] loss: 1.274
[2m[36m(pid=1102)[0m [7,  4000] loss: 0.644
[2m[36m(pid=1102)[0m [7,  6000] loss: 0.437
[2m[36m(pid=1102)[0m [7,  8000] loss: 0.323
[2m[36m(pid=1102)[0m [7, 10000] loss: 0.261
[2m[36m(pid=1102)[0m [7, 12000] loss: 0.215
[2m[36m(pid=1102)[0m [7, 14000] loss: 0.186
[2m[36m(pid=1102)[0m [7, 16000] loss: 0.163
[2m[36m(pid=1102)[0m [7, 18000] loss: 0.142
[2m[36m(pid=1102)[0m [7, 20000] loss: 0.130
Result for DEFAULT_3be5d_00006:
  accuracy: 0.5446
  date: 2020-10-02_16-23-59
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 7
  loss: 1.295015395489335
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 618.3158802986145
  time_this_iter_s: 82.7914457321167
  time_total_s: 618.3158802986145
  timestamp: 1601655839
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.5600497658133508 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.29502 |     0.5446 |                    7 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |                 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [8,  2000] loss: 1.279
[2m[36m(pid=1102)[0m [8,  4000] loss: 0.634
[2m[36m(pid=1102)[0m [8,  6000] loss: 0.424
[2m[36m(pid=1102)[0m [8,  8000] loss: 0.329
[2m[36m(pid=1102)[0m [8, 10000] loss: 0.256
[2m[36m(pid=1102)[0m [8, 12000] loss: 0.211
[2m[36m(pid=1102)[0m [8, 14000] loss: 0.186
[2m[36m(pid=1102)[0m [8, 16000] loss: 0.159
[2m[36m(pid=1102)[0m [8, 18000] loss: 0.146
[2m[36m(pid=1102)[0m [8, 20000] loss: 0.127
Result for DEFAULT_3be5d_00006:
  accuracy: 0.5261
  date: 2020-10-02_16-25-22
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 8
  loss: 1.347460748058674
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 701.1527426242828
  time_this_iter_s: 82.83686232566833
  time_total_s: 701.1527426242828
  timestamp: 1601655922
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.347460748058674 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.34746 |     0.5261 |                    8 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |                 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [9,  2000] loss: 1.254
[2m[36m(pid=1102)[0m [9,  4000] loss: 0.634
[2m[36m(pid=1102)[0m [9,  6000] loss: 0.421
[2m[36m(pid=1102)[0m [9,  8000] loss: 0.315
[2m[36m(pid=1102)[0m [9, 10000] loss: 0.255
[2m[36m(pid=1102)[0m [9, 12000] loss: 0.217
[2m[36m(pid=1102)[0m [9, 14000] loss: 0.182
[2m[36m(pid=1102)[0m [9, 16000] loss: 0.158
[2m[36m(pid=1102)[0m [9, 18000] loss: 0.141
[2m[36m(pid=1102)[0m [9, 20000] loss: 0.128
Result for DEFAULT_3be5d_00006:
  accuracy: 0.5338
  date: 2020-10-02_16-26-45
  done: false
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 9
  loss: 1.3398598799956032
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 784.2477519512177
  time_this_iter_s: 83.09500932693481
  time_total_s: 784.2477519512177
  timestamp: 1601656005
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.347460748058674 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.33986 |     0.5338 |                    9 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |                 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1102)[0m [10,  2000] loss: 1.256
[2m[36m(pid=1102)[0m [10,  4000] loss: 0.630
[2m[36m(pid=1102)[0m [10,  6000] loss: 0.417
[2m[36m(pid=1102)[0m [10,  8000] loss: 0.312
[2m[36m(pid=1102)[0m [10, 10000] loss: 0.252
[2m[36m(pid=1102)[0m [10, 12000] loss: 0.210
[2m[36m(pid=1102)[0m [10, 14000] loss: 0.185
[2m[36m(pid=1102)[0m [10, 16000] loss: 0.159
[2m[36m(pid=1102)[0m [10, 18000] loss: 0.141
[2m[36m(pid=1102)[0m [10, 20000] loss: 0.125
Result for DEFAULT_3be5d_00006:
  accuracy: 0.5331
  date: 2020-10-02_16-28-08
  done: true
  experiment_id: c1c79445738142f6be08fdc82f097faf
  experiment_tag: 6_batch_size=2,l1=8,l2=8,lr=0.00087038
  hostname: db608dfe860a
  iterations_since_restore: 10
  loss: 1.3442331326473504
  node_ip: 172.17.0.2
  pid: 1102
  should_checkpoint: true
  time_since_restore: 867.8894438743591
  time_this_iter_s: 83.64169192314148
  time_total_s: 867.8894438743591
  timestamp: 1601656088
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 3be5d_00006

== Status ==
Memory usage on this node: 4.1/240.1 GiB
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -1.347460748058674 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |                 |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |                 |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |                 |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |                 |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |                 |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |                 |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | RUNNING    | 172.17.0.2:1102 |            2 |    8 |    8 | 0.000870384 | 1.34423 |     0.5331 |                   10 |
| DEFAULT_3be5d_00007 | TERMINATED |                 |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |                 |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |                 |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


== Status ==
Memory usage on this node: 4.1/240.1 GiB
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -1.347460748058674 | Iter 4.000: -1.3845566206591204 | Iter 2.000: -1.4978141681149602 | Iter 1.000: -2.1348158064130693
Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/157.76 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (10 TERMINATED)
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_3be5d_00000 | TERMINATED |       |            8 |    4 |   64 | 0.040451    | 2.32011 |     0.0995 |                    1 |
| DEFAULT_3be5d_00001 | TERMINATED |       |            2 |   16 |   64 | 0.081644    | 2.47513 |     0.1036 |                    1 |
| DEFAULT_3be5d_00002 | TERMINATED |       |           16 |   64 |  256 | 0.0338347   | 1.95347 |     0.2371 |                   10 |
| DEFAULT_3be5d_00003 | TERMINATED |       |            4 |   16 |  256 | 0.0534941   | 2.32857 |     0.1001 |                    1 |
| DEFAULT_3be5d_00004 | TERMINATED |       |            8 |    4 |    4 | 0.000265259 | 2.29537 |     0.1021 |                    1 |
| DEFAULT_3be5d_00005 | TERMINATED |       |            2 |   64 |   64 | 0.000253839 | 1.49781 |     0.4613 |                    2 |
| DEFAULT_3be5d_00006 | TERMINATED |       |            2 |    8 |    8 | 0.000870384 | 1.34423 |     0.5331 |                   10 |
| DEFAULT_3be5d_00007 | TERMINATED |       |            2 |  128 |   32 | 0.00471899  | 1.95703 |     0.2501 |                    2 |
| DEFAULT_3be5d_00008 | TERMINATED |       |            4 |   16 |  256 | 0.0263969   | 2.31249 |     0.0994 |                    1 |
| DEFAULT_3be5d_00009 | TERMINATED |       |            8 |   32 |  256 | 0.00178228  | 1.22355 |     0.5738 |                   10 |
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


Best trial config: {'l1': 32, 'l2': 256, 'lr': 0.0017822783356499282, 'batch_size': 8}
Best trial final validation loss: 1.2235519858837127
Best trial final validation accuracy: 0.5738
Files already downloaded and verified
Files already downloaded and verified
Best trial test set accuracy: 0.582
</pre></div>
</div>
<p>If you run the code, an example output could look like this:</p>
<p>Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.</p>
<p>So that’s it! You can now tune the parameters of your PyTorch models.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 14 minutes  46.903 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/95074cd7ce8c3e57a92e7a9c49182e6a/hyperparameter_tuning_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">hyperparameter_tuning_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/c24b93738bc036c1b66d0387555bf69a/hyperparameter_tuning_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">hyperparameter_tuning_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="../advanced/dispatcher.html" rel="prev" title="Registering a Dispatched Operator in C++"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr class="helpful-hr hr-top"/>
<div class="helpful-container">
<div class="helpful-question">Was this helpful?</div>
<div class="helpful-question yes-link" data-behavior="was-this-helpful-event" data-response="yes">Yes</div>
<div class="helpful-question no-link" data-behavior="was-this-helpful-event" data-response="no">No</div>
<div class="was-helpful-thank-you">Thank you</div>
</div>
<hr class="helpful-hr hr-bottom"/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Hyperparameter tuning with Ray Tune</a><ul>
<li><a class="reference internal" href="#setup-imports">Setup / Imports</a></li>
<li><a class="reference internal" href="#data-loaders">Data loaders</a></li>
<li><a class="reference internal" href="#configurable-neural-network">Configurable neural network</a></li>
<li><a class="reference internal" href="#the-train-function">The train function</a><ul>
<li><a class="reference internal" href="#adding-multi-gpu-support-with-dataparallel">Adding (multi) GPU support with DataParallel</a></li>
<li><a class="reference internal" href="#communicating-with-ray-tune">Communicating with Ray Tune</a></li>
<li><a class="reference internal" href="#full-training-function">Full training function</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-set-accuracy">Test set accuracy</a></li>
<li><a class="reference internal" href="#configuring-the-search-space">Configuring the search space</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>
<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Download',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   $("[data-behavior='was-this-helpful-event']").on('click', function(){
    $(".helpful-question").hide();
    $(".was-helpful-thank-you").show();
    fbq('trackCustom', "Was this Helpful?", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      helpful: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Was this Helpful?',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
    gtag('event', $(this).attr("data-response"), {
      'event_category': 'Was this Helpful?',
      'event_label': $("h1").first().text()
    });
   });

   if (location.pathname == "/") {
     $(".helpful-container").hide();
     $(".hr-bottom").hide();
   }
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1"/>
</noscript>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Stay Connected</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
<a class="youtube" href="https://www.youtube.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg">
</img></div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/features">Features</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/hub">PyTorch Hub</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>