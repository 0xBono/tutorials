
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Hyperparameter tuning with Ray Tune — PyTorch Tutorials 1.6.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial"/>
<link href="../advanced/dispatcher.html" rel="prev" title="Registering a Dispatched Operator in C++"/>
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<div class="ecosystem-dropdown">
<a data-toggle="ecosystem-dropdown" id="dropdownMenuButton">
                Ecosystem
              </a>
<div class="ecosystem-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
<span class="dropdown-title">Tools &amp; Libraries</span>
<p>Explore the ecosystem of tools and libraries</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<div class="resources-dropdown">
<a data-toggle="resources-dropdown" id="resourcesDropdownButton">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.6.0
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption"><span class="caption-text">Image/Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_preprocessing_tutorial.html">Audio I/O and Pre-Processing with torchaudio</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_sentiment_ngrams_tutorial.html">Text Classification with TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtext_translation_tutorial.html">Language Translation with TorchText</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
</ul>
<p class="caption"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/named_tensor_tutorial.html">(prototype) Introduction to Named Tensors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Hyperparameter tuning with Ray Tune</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/hyperparameter_tuning_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/hyperparameter_tuning_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="hyperparameter-tuning-with-ray-tune">
<span id="sphx-glr-beginner-hyperparameter-tuning-tutorial-py"></span><h1>Hyperparameter tuning with Ray Tune<a class="headerlink" href="#hyperparameter-tuning-with-ray-tune" title="Permalink to this headline">¶</a></h1>
<p>Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.</p>
<p>Fortunately, there are tools that help with finding the best combination of parameters.
<a class="reference external" href="https://docs.ray.io/en/latest/tune.html">Ray Tune</a> is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through <a class="reference external" href="https://ray.io/">Ray’s distributed machine learning engine</a>.</p>
<p>In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">this tutorial from the PyTorch documentation</a> for training
a CIFAR10 image classifier.</p>
<p>As you will see, we only need to add some slight modifications. In particular, we
need to</p>
<ol class="arabic simple">
<li>wrap data loading and training in functions,</li>
<li>make some network parameters configurable,</li>
<li>add checkpointing (optional),</li>
<li>and define the search space for the model tuning</li>
</ol>
<div class="line-block">
<div class="line"><br/></div>
</div>
<p>To run this tutorial, please make sure the following packages are
installed:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">ray[tune]</span></code>: Distributed hyperparameter tuning library</li>
<li><code class="docutils literal notranslate"><span class="pre">torchvision</span></code>: For the data transformers</li>
</ul>
<div class="section" id="setup-imports">
<h2>Setup / Imports<a class="headerlink" href="#setup-imports" title="Permalink to this headline">¶</a></h2>
<p>Let’s start with the imports:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">tune</span>
<span class="kn">from</span> <span class="nn">ray.tune</span> <span class="kn">import</span> <span class="n">CLIReporter</span>
<span class="kn">from</span> <span class="nn">ray.tune.schedulers</span> <span class="kn">import</span> <span class="n">ASHAScheduler</span>
</pre></div>
</div>
<p>Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.</p>
</div>
<div class="section" id="data-loaders">
<h2>Data loaders<a class="headerlink" href="#data-loaders" title="Permalink to this headline">¶</a></h2>
<p>We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="o">=</span><span class="s2">"./data"</span><span class="p">):</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="p">])</span>

    <span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span>
</pre></div>
</div>
</div>
<div class="section" id="configurable-neural-network">
<h2>Configurable neural network<a class="headerlink" href="#configurable-neural-network" title="Permalink to this headline">¶</a></h2>
<p>We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l1</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mi">84</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="n">l1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<div class="section" id="the-train-function">
<h2>The train function<a class="headerlink" href="#the-train-function" title="Permalink to this headline">¶</a></h2>
<p>Now it gets interesting, because we introduce some changes to the example <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">from the PyTorch
documentation</a>.</p>
<p>We wrap the training script in a function <code class="docutils literal notranslate"><span class="pre">train_cifar(config,</span> <span class="pre">checkpoint_dir=None,</span> <span class="pre">data_dir=None)</span></code>.
As you can guess, the <code class="docutils literal notranslate"><span class="pre">config</span></code> parameter will receive the hyperparameters we would like to
train with. The <code class="docutils literal notranslate"><span class="pre">checkpoint_dir</span></code> parameter is used to restore checkpoints. The <code class="docutils literal notranslate"><span class="pre">data_dir</span></code> specifies
the directory where we load and store the data, so multiple runs can share the same data source.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

<span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>
</pre></div>
</div>
<p>The learning rate of the optimizer is made configurable, too:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<p>We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.</p>
<div class="section" id="adding-multi-gpu-support-with-dataparallel">
<h3>Adding (multi) GPU support with DataParallel<a class="headerlink" href="#adding-multi-gpu-support-with-dataparallel" title="Permalink to this headline">¶</a></h3>
<p>Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch’s abstractions in Ray Tune. Thus, we can wrap our model in <code class="docutils literal notranslate"><span class="pre">nn.DataParallel</span></code>
to support data parallel training on multiple GPUs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>By using a <code class="docutils literal notranslate"><span class="pre">device</span></code> variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports <a class="reference external" href="https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus">fractional GPUs</a>
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We’ll come back
to that later.</p>
</div>
<div class="section" id="communicating-with-ray-tune">
<h3>Communicating with Ray Tune<a class="headerlink" href="#communicating-with-ray-tune" title="Permalink to this headline">¶</a></h3>
<p>The most interesting part is the communication with Ray Tune:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

<span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.</p>
<p>The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
<a class="reference external" href="https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html">Population Based Training</a>.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.</p>
</div>
<div class="section" id="full-training-function">
<h3>Full training function<a class="headerlink" href="#full-training-function" title="Permalink to this headline">¶</a></h3>
<p>The full code example looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_cifar</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
        <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>

    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>

    <span class="n">test_abs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
    <span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
        <span class="n">trainset</span><span class="p">,</span> <span class="p">[</span><span class="n">test_abs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_abs</span><span class="p">])</span>

    <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">train_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">valloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">val_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">epoch_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># get the inputs; data is a list of [inputs, labels]</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># zero the parameter gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># forward + backward + optimize</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># print statistics</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">epoch_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2000</span> <span class="o">==</span> <span class="mi">1999</span><span class="p">:</span>  <span class="c1"># print every 2000 mini-batches</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"[</span><span class="si">%d</span><span class="s2">, </span><span class="si">%5d</span><span class="s2">] loss: </span><span class="si">%.3f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                <span class="n">running_loss</span> <span class="o">/</span> <span class="n">epoch_steps</span><span class="p">))</span>
                <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c1"># Validation loss</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">val_steps</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Finished Training"</span><span class="p">)</span>
</pre></div>
</div>
<p>As you can see, most of the code is adapted directly from the original example.</p>
</div>
</div>
<div class="section" id="test-set-accuracy">
<h2>Test set accuracy<a class="headerlink" href="#test-set-accuracy" title="Permalink to this headline">¶</a></h2>
<p>Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">):</span>
    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

    <span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</pre></div>
</div>
<p>The function also expects a <code class="docutils literal notranslate"><span class="pre">device</span></code> parameter, so we can do the
test set validation on a GPU.</p>
</div>
<div class="section" id="configuring-the-search-space">
<h2>Configuring the search space<a class="headerlink" href="#configuring-the-search-space" title="Permalink to this headline">¶</a></h2>
<p>Lastly, we need to define Ray Tune’s search space. Here is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">tune.sample_from()</span></code> function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the <code class="docutils literal notranslate"><span class="pre">l1</span></code> and <code class="docutils literal notranslate"><span class="pre">l2</span></code> parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The <code class="docutils literal notranslate"><span class="pre">lr</span></code> (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.</p>
<p>At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the <code class="docutils literal notranslate"><span class="pre">ASHAScheduler</span></code> which will terminate bad
performing trials early.</p>
<p>We wrap the <code class="docutils literal notranslate"><span class="pre">train_cifar</span></code> function with <code class="docutils literal notranslate"><span class="pre">functools.partial</span></code> to set the constant
<code class="docutils literal notranslate"><span class="pre">data_dir</span></code> parameter. We can also tell Ray Tune what resources should be
available for each trial:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gpus_per_trial</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># ...</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
    <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">,</span>
    <span class="n">checkpoint_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>You can specify the number of CPUs, which are then available e.g.
to increase the <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> of the PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven’t been requested for them - so you don’t have to care about two trials
using the same set of resources.</p>
<p>Here we can also specify fractional GPUs, so something like <code class="docutils literal notranslate"><span class="pre">gpus_per_trial=0.5</span></code> is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.</p>
<p>After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.</p>
<p>The full main function looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">"./data"</span><span class="p">)</span>
    <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
        <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
    <span class="p">}</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">ASHAScheduler</span><span class="p">(</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">"loss"</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">"min"</span><span class="p">,</span>
        <span class="n">max_t</span><span class="o">=</span><span class="n">max_num_epochs</span><span class="p">,</span>
        <span class="n">grace_period</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">reporter</span> <span class="o">=</span> <span class="n">CLIReporter</span><span class="p">(</span>
        <span class="c1"># parameter_columns=["l1", "l2", "lr", "batch_size"],</span>
        <span class="n">metric_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"training_iteration"</span><span class="p">])</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
        <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">)</span>

    <span class="n">best_trial</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">get_best_trial</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"min"</span><span class="p">,</span> <span class="s2">"last"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial config: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation loss: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">]))</span>

    <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">gpus_per_trial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">)</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">best_checkpoint_dir</span> <span class="o">=</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">value</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">best_checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>

    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_accuracy</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial test set accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="c1"># You can change the number of GPUs per trial here:</span>
    <span class="n">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
Files already downloaded and verified
== Status ==
Memory usage on this node: 4.2/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (9 PENDING, 1 RUNNING)
+---------------------+----------+-------+--------------+------+------+-------------+
| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |
|---------------------+----------+-------+--------------+------+------+-------------|
| DEFAULT_2714c_00000 | RUNNING  |       |            2 |   32 |  128 | 0.000342167 |
| DEFAULT_2714c_00001 | PENDING  |       |            2 |   16 |  256 | 0.00101973  |
| DEFAULT_2714c_00002 | PENDING  |       |           16 |    4 |    8 | 0.00010686  |
| DEFAULT_2714c_00003 | PENDING  |       |            2 |   32 |    8 | 0.00117706  |
| DEFAULT_2714c_00004 | PENDING  |       |            2 |   32 |    8 | 0.0592514   |
| DEFAULT_2714c_00005 | PENDING  |       |           16 |   64 |    8 | 0.000324236 |
| DEFAULT_2714c_00006 | PENDING  |       |           16 |    8 |   32 | 0.00338091  |
| DEFAULT_2714c_00007 | PENDING  |       |           16 |  256 |  128 | 0.0544753   |
| DEFAULT_2714c_00008 | PENDING  |       |            2 |   16 |   16 | 0.0594805   |
| DEFAULT_2714c_00009 | PENDING  |       |            2 |  256 |    8 | 0.00435915  |
+---------------------+----------+-------+--------------+------+------+-------------+


[2m[36m(pid=2333)[0m Files already downloaded and verified
[2m[36m(pid=2299)[0m Files already downloaded and verified
[2m[36m(pid=2331)[0m Files already downloaded and verified
[2m[36m(pid=2315)[0m Files already downloaded and verified
[2m[36m(pid=2313)[0m Files already downloaded and verified
[2m[36m(pid=2317)[0m Files already downloaded and verified
[2m[36m(pid=2289)[0m Files already downloaded and verified
[2m[36m(pid=2264)[0m Files already downloaded and verified
[2m[36m(pid=2319)[0m Files already downloaded and verified
[2m[36m(pid=2304)[0m Files already downloaded and verified
[2m[36m(pid=2315)[0m Files already downloaded and verified
[2m[36m(pid=2313)[0m Files already downloaded and verified
[2m[36m(pid=2289)[0m Files already downloaded and verified
[2m[36m(pid=2333)[0m Files already downloaded and verified
[2m[36m(pid=2299)[0m Files already downloaded and verified
[2m[36m(pid=2331)[0m Files already downloaded and verified
[2m[36m(pid=2317)[0m Files already downloaded and verified
[2m[36m(pid=2264)[0m Files already downloaded and verified
[2m[36m(pid=2319)[0m Files already downloaded and verified
[2m[36m(pid=2304)[0m Files already downloaded and verified
[2m[36m(pid=2331)[0m [1,  2000] loss: 2.175
[2m[36m(pid=2264)[0m [1,  2000] loss: 2.366
[2m[36m(pid=2319)[0m [1,  2000] loss: 2.180
[2m[36m(pid=2299)[0m [1,  2000] loss: 2.303
[2m[36m(pid=2317)[0m [1,  2000] loss: 2.376
[2m[36m(pid=2289)[0m [1,  2000] loss: 2.225
[2m[36m(pid=2304)[0m [1,  2000] loss: 1.886
[2m[36m(pid=2315)[0m [1,  2000] loss: 2.314
[2m[36m(pid=2333)[0m [1,  2000] loss: 2.324
[2m[36m(pid=2313)[0m [1,  2000] loss: 2.084
[2m[36m(pid=2331)[0m [1,  4000] loss: 0.941
[2m[36m(pid=2264)[0m [1,  4000] loss: 1.186
[2m[36m(pid=2319)[0m [1,  4000] loss: 0.980
[2m[36m(pid=2299)[0m [1,  4000] loss: 1.143
[2m[36m(pid=2317)[0m [1,  4000] loss: 1.184
[2m[36m(pid=2289)[0m [1,  4000] loss: 1.025
Result for DEFAULT_2714c_00006:
  accuracy: 0.4294
  date: 2020-10-27_14-53-50
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 1.538083573436737
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 30.03333616256714
  time_this_iter_s: 30.03333616256714
  time_total_s: 30.03333616256714
  timestamp: 1603810430
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 8.8/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.538083573436737
Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (10 RUNNING)
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING  |                 |            2 |   32 |  128 | 0.000342167 |         |            |                      |
| DEFAULT_2714c_00001 | RUNNING  |                 |            2 |   16 |  256 | 0.00101973  |         |            |                      |
| DEFAULT_2714c_00002 | RUNNING  |                 |           16 |    4 |    8 | 0.00010686  |         |            |                      |
| DEFAULT_2714c_00003 | RUNNING  |                 |            2 |   32 |    8 | 0.00117706  |         |            |                      |
| DEFAULT_2714c_00004 | RUNNING  |                 |            2 |   32 |    8 | 0.0592514   |         |            |                      |
| DEFAULT_2714c_00005 | RUNNING  |                 |           16 |   64 |    8 | 0.000324236 |         |            |                      |
| DEFAULT_2714c_00006 | RUNNING  | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.53808 |     0.4294 |                    1 |
| DEFAULT_2714c_00007 | RUNNING  |                 |           16 |  256 |  128 | 0.0544753   |         |            |                      |
| DEFAULT_2714c_00008 | RUNNING  |                 |            2 |   16 |   16 | 0.0594805   |         |            |                      |
| DEFAULT_2714c_00009 | RUNNING  |                 |            2 |  256 |    8 | 0.00435915  |         |            |                      |
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_2714c_00005:
  accuracy: 0.1124
  date: 2020-10-27_14-53-51
  done: true
  experiment_id: bbc59d694e7a4b2c9513dc54245137e7
  experiment_tag: 5_batch_size=16,l1=64,l2=8,lr=0.00032424
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 2.3034431701660156
  node_ip: 172.17.0.2
  pid: 2315
  should_checkpoint: true
  time_since_restore: 31.005838871002197
  time_this_iter_s: 31.005838871002197
  time_total_s: 31.005838871002197
  timestamp: 1603810431
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00005

Result for DEFAULT_2714c_00002:
  accuracy: 0.0975
  date: 2020-10-27_14-53-51
  done: true
  experiment_id: e9cabfe406c24a7285172623d14560c3
  experiment_tag: 2_batch_size=16,l1=4,l2=8,lr=0.00010686
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 2.3088967502593993
  node_ip: 172.17.0.2
  pid: 2333
  should_checkpoint: true
  time_since_restore: 31.146920204162598
  time_this_iter_s: 31.146920204162598
  time_total_s: 31.146920204162598
  timestamp: 1603810431
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00002

Result for DEFAULT_2714c_00007:
  accuracy: 0.252
  date: 2020-10-27_14-53-53
  done: false
  experiment_id: 3a43868f58814abd91bafcb2e234c900
  experiment_tag: 7_batch_size=16,l1=256,l2=128,lr=0.054475
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 1.9874404485702515
  node_ip: 172.17.0.2
  pid: 2313
  should_checkpoint: true
  time_since_restore: 32.901124715805054
  time_this_iter_s: 32.901124715805054
  time_total_s: 32.901124715805054
  timestamp: 1603810433
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00007

[2m[36m(pid=2331)[0m [1,  6000] loss: 0.581
[2m[36m(pid=2264)[0m [1,  6000] loss: 0.790
[2m[36m(pid=2319)[0m [1,  6000] loss: 0.614
[2m[36m(pid=2299)[0m [1,  6000] loss: 0.717
[2m[36m(pid=2317)[0m [1,  6000] loss: 0.792
[2m[36m(pid=2289)[0m [1,  6000] loss: 0.658
[2m[36m(pid=2304)[0m [2,  2000] loss: 1.481
[2m[36m(pid=2331)[0m [1,  8000] loss: 0.415
[2m[36m(pid=2319)[0m [1,  8000] loss: 0.443
[2m[36m(pid=2264)[0m [1,  8000] loss: 0.593
[2m[36m(pid=2299)[0m [1,  8000] loss: 0.484
[2m[36m(pid=2317)[0m [1,  8000] loss: 0.594
[2m[36m(pid=2289)[0m [1,  8000] loss: 0.489
[2m[36m(pid=2313)[0m [2,  2000] loss: 2.140
Result for DEFAULT_2714c_00006:
  accuracy: 0.4777
  date: 2020-10-27_14-54-11
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 2
  loss: 1.4154450684547424
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 50.8400616645813
  time_this_iter_s: 20.80672550201416
  time_total_s: 50.8400616645813
  timestamp: 1603810451
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 7.9/240.1 GiB
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.4154450684547424 | Iter 1.000: -2.1454418093681333
Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (8 RUNNING, 2 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    |                 |            2 |   32 |  128 | 0.000342167 |         |            |                      |
| DEFAULT_2714c_00001 | RUNNING    |                 |            2 |   16 |  256 | 0.00101973  |         |            |                      |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.00117706  |         |            |                      |
| DEFAULT_2714c_00004 | RUNNING    |                 |            2 |   32 |    8 | 0.0592514   |         |            |                      |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.41545 |     0.4777 |                    2 |
| DEFAULT_2714c_00007 | RUNNING    | 172.17.0.2:2313 |           16 |  256 |  128 | 0.0544753   | 1.98744 |     0.252  |                    1 |
| DEFAULT_2714c_00008 | RUNNING    |                 |            2 |   16 |   16 | 0.0594805   |         |            |                      |
| DEFAULT_2714c_00009 | RUNNING    |                 |            2 |  256 |    8 | 0.00435915  |         |            |                      |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2331)[0m [1, 10000] loss: 0.324
[2m[36m(pid=2319)[0m [1, 10000] loss: 0.337
[2m[36m(pid=2264)[0m [1, 10000] loss: 0.475
[2m[36m(pid=2299)[0m [1, 10000] loss: 0.362
[2m[36m(pid=2317)[0m [1, 10000] loss: 0.474
Result for DEFAULT_2714c_00007:
  accuracy: 0.1509
  date: 2020-10-27_14-54-18
  done: true
  experiment_id: 3a43868f58814abd91bafcb2e234c900
  experiment_tag: 7_batch_size=16,l1=256,l2=128,lr=0.054475
  hostname: efccb162df23
  iterations_since_restore: 2
  loss: 2.2226379470825197
  node_ip: 172.17.0.2
  pid: 2313
  should_checkpoint: true
  time_since_restore: 57.91364574432373
  time_this_iter_s: 25.012521028518677
  time_total_s: 57.91364574432373
  timestamp: 1603810458
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 2714c_00007

== Status ==
Memory usage on this node: 7.9/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.1454418093681333
Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (8 RUNNING, 2 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    |                 |            2 |   32 |  128 | 0.000342167 |         |            |                      |
| DEFAULT_2714c_00001 | RUNNING    |                 |            2 |   16 |  256 | 0.00101973  |         |            |                      |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.00117706  |         |            |                      |
| DEFAULT_2714c_00004 | RUNNING    |                 |            2 |   32 |    8 | 0.0592514   |         |            |                      |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.41545 |     0.4777 |                    2 |
| DEFAULT_2714c_00007 | RUNNING    | 172.17.0.2:2313 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | RUNNING    |                 |            2 |   16 |   16 | 0.0594805   |         |            |                      |
| DEFAULT_2714c_00009 | RUNNING    |                 |            2 |  256 |    8 | 0.00435915  |         |            |                      |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2289)[0m [1, 10000] loss: 0.391
[2m[36m(pid=2319)[0m [1, 12000] loss: 0.274
[2m[36m(pid=2331)[0m [1, 12000] loss: 0.265
[2m[36m(pid=2264)[0m [1, 12000] loss: 0.395
[2m[36m(pid=2299)[0m [1, 12000] loss: 0.287
[2m[36m(pid=2317)[0m [1, 12000] loss: 0.396
[2m[36m(pid=2304)[0m [3,  2000] loss: 1.361
[2m[36m(pid=2289)[0m [1, 12000] loss: 0.320
[2m[36m(pid=2331)[0m [1, 14000] loss: 0.221
[2m[36m(pid=2319)[0m [1, 14000] loss: 0.231
[2m[36m(pid=2264)[0m [1, 14000] loss: 0.338
Result for DEFAULT_2714c_00006:
  accuracy: 0.5083
  date: 2020-10-27_14-54-31
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 3
  loss: 1.348125759124756
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 71.18589687347412
  time_this_iter_s: 20.345835208892822
  time_total_s: 71.18589687347412
  timestamp: 1603810471
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 7.3/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.1454418093681333
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    |                 |            2 |   32 |  128 | 0.000342167 |         |            |                      |
| DEFAULT_2714c_00001 | RUNNING    |                 |            2 |   16 |  256 | 0.00101973  |         |            |                      |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.00117706  |         |            |                      |
| DEFAULT_2714c_00004 | RUNNING    |                 |            2 |   32 |    8 | 0.0592514   |         |            |                      |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.34813 |     0.5083 |                    3 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | RUNNING    |                 |            2 |   16 |   16 | 0.0594805   |         |            |                      |
| DEFAULT_2714c_00009 | RUNNING    |                 |            2 |  256 |    8 | 0.00435915  |         |            |                      |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [1, 14000] loss: 0.237
[2m[36m(pid=2317)[0m [1, 14000] loss: 0.338
[2m[36m(pid=2289)[0m [1, 14000] loss: 0.281
[2m[36m(pid=2331)[0m [1, 16000] loss: 0.191
[2m[36m(pid=2319)[0m [1, 16000] loss: 0.200
[2m[36m(pid=2264)[0m [1, 16000] loss: 0.297
[2m[36m(pid=2299)[0m [1, 16000] loss: 0.201
[2m[36m(pid=2317)[0m [1, 16000] loss: 0.296
[2m[36m(pid=2304)[0m [4,  2000] loss: 1.300
[2m[36m(pid=2331)[0m [1, 18000] loss: 0.173
[2m[36m(pid=2319)[0m [1, 18000] loss: 0.175
[2m[36m(pid=2264)[0m [1, 18000] loss: 0.263
[2m[36m(pid=2289)[0m [1, 16000] loss: 0.244
[2m[36m(pid=2299)[0m [1, 18000] loss: 0.173
[2m[36m(pid=2317)[0m [1, 18000] loss: 0.263
Result for DEFAULT_2714c_00006:
  accuracy: 0.5221
  date: 2020-10-27_14-54-51
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 4
  loss: 1.3235916884422303
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 91.14441752433777
  time_this_iter_s: 19.958520650863647
  time_total_s: 91.14441752433777
  timestamp: 1603810491
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 7.3/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.1454418093681333
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    |                 |            2 |   32 |  128 | 0.000342167 |         |            |                      |
| DEFAULT_2714c_00001 | RUNNING    |                 |            2 |   16 |  256 | 0.00101973  |         |            |                      |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    |                 |            2 |   32 |    8 | 0.00117706  |         |            |                      |
| DEFAULT_2714c_00004 | RUNNING    |                 |            2 |   32 |    8 | 0.0592514   |         |            |                      |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.32359 |     0.5221 |                    4 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | RUNNING    |                 |            2 |   16 |   16 | 0.0594805   |         |            |                      |
| DEFAULT_2714c_00009 | RUNNING    |                 |            2 |  256 |    8 | 0.00435915  |         |            |                      |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2331)[0m [1, 20000] loss: 0.151
[2m[36m(pid=2319)[0m [1, 20000] loss: 0.155
[2m[36m(pid=2264)[0m [1, 20000] loss: 0.237
[2m[36m(pid=2299)[0m [1, 20000] loss: 0.154
[2m[36m(pid=2289)[0m [1, 18000] loss: 0.217
[2m[36m(pid=2317)[0m [1, 20000] loss: 0.237
[2m[36m(pid=2304)[0m [5,  2000] loss: 1.265
[2m[36m(pid=2289)[0m [1, 20000] loss: 0.194
Result for DEFAULT_2714c_00003:
  accuracy: 0.3997
  date: 2020-10-27_14-55-09
  done: false
  experiment_id: 4641904849b44d0d947c2224ac967bb0
  experiment_tag: 3_batch_size=2,l1=32,l2=8,lr=0.0011771
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 1.6323326272882521
  node_ip: 172.17.0.2
  pid: 2319
  should_checkpoint: true
  time_since_restore: 108.98559474945068
  time_this_iter_s: 108.98559474945068
  time_total_s: 108.98559474945068
  timestamp: 1603810509
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00003

== Status ==
Memory usage on this node: 7.3/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.819041507768631 | Iter 1.000: -1.9874404485702515
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    |                 |            2 |   32 |  128 | 0.000342167 |         |            |                      |
| DEFAULT_2714c_00001 | RUNNING    |                 |            2 |   16 |  256 | 0.00101973  |         |            |                      |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.63233 |     0.3997 |                    1 |
| DEFAULT_2714c_00004 | RUNNING    |                 |            2 |   32 |    8 | 0.0592514   |         |            |                      |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.32359 |     0.5221 |                    4 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | RUNNING    |                 |            2 |   16 |   16 | 0.0594805   |         |            |                      |
| DEFAULT_2714c_00009 | RUNNING    |                 |            2 |  256 |    8 | 0.00435915  |         |            |                      |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_2714c_00001:
  accuracy: 0.4491
  date: 2020-10-27_14-55-09
  done: false
  experiment_id: de0c51a9658d467db512b0e041c9fc29
  experiment_tag: 1_batch_size=2,l1=16,l2=256,lr=0.0010197
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 1.491199586597085
  node_ip: 172.17.0.2
  pid: 2331
  should_checkpoint: true
  time_since_restore: 109.1725161075592
  time_this_iter_s: 109.1725161075592
  time_total_s: 109.1725161075592
  timestamp: 1603810509
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00001

Result for DEFAULT_2714c_00008:
  accuracy: 0.0981
  date: 2020-10-27_14-55-10
  done: true
  experiment_id: 9e614da3ed6740b3ad55837d8e205794
  experiment_tag: 8_batch_size=2,l1=16,l2=16,lr=0.05948
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 2.354786848306656
  node_ip: 172.17.0.2
  pid: 2264
  should_checkpoint: true
  time_since_restore: 109.50301504135132
  time_this_iter_s: 109.50301504135132
  time_total_s: 109.50301504135132
  timestamp: 1603810510
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00008

Result for DEFAULT_2714c_00000:
  accuracy: 0.4545
  date: 2020-10-27_14-55-11
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 1.4980355892919004
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 110.85097455978394
  time_this_iter_s: 110.85097455978394
  time_total_s: 110.85097455978394
  timestamp: 1603810511
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00000

Result for DEFAULT_2714c_00006:
  accuracy: 0.5543
  date: 2020-10-27_14-55-12
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 5
  loss: 1.2612181503772735
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 111.67007374763489
  time_this_iter_s: 20.52565622329712
  time_total_s: 111.67007374763489
  timestamp: 1603810512
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 2714c_00006

Result for DEFAULT_2714c_00004:
  accuracy: 0.0976
  date: 2020-10-27_14-55-13
  done: true
  experiment_id: f5abb591429e42aeb6012e220b35a790
  experiment_tag: 4_batch_size=2,l1=32,l2=8,lr=0.059251
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 2.432968303322792
  node_ip: 172.17.0.2
  pid: 2317
  should_checkpoint: true
  time_since_restore: 112.66052722930908
  time_this_iter_s: 112.66052722930908
  time_total_s: 112.66052722930908
  timestamp: 1603810513
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00004

[2m[36m(pid=2319)[0m [2,  2000] loss: 1.508
[2m[36m(pid=2331)[0m [2,  2000] loss: 1.473
[2m[36m(pid=2299)[0m [2,  2000] loss: 1.487
Result for DEFAULT_2714c_00009:
  accuracy: 0.2342
  date: 2020-10-27_14-55-21
  done: true
  experiment_id: 9d65772079c3404c86d44a099ec36978
  experiment_tag: 9_batch_size=2,l1=256,l2=8,lr=0.0043591
  hostname: efccb162df23
  iterations_since_restore: 1
  loss: 2.1763338674962522
  node_ip: 172.17.0.2
  pid: 2289
  should_checkpoint: true
  time_since_restore: 120.91966795921326
  time_this_iter_s: 120.91966795921326
  time_total_s: 120.91966795921326
  timestamp: 1603810521
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 2714c_00009

== Status ==
Memory usage on this node: 6.3/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: None | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.081887158033252
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.49804 |     0.4545 |                    1 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.4912  |     0.4491 |                    1 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.63233 |     0.3997 |                    1 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.26122 |     0.5543 |                    5 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | RUNNING    | 172.17.0.2:2289 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2319)[0m [2,  4000] loss: 0.752
[2m[36m(pid=2304)[0m [6,  2000] loss: 1.229
[2m[36m(pid=2331)[0m [2,  4000] loss: 0.739
[2m[36m(pid=2299)[0m [2,  4000] loss: 0.738
Result for DEFAULT_2714c_00006:
  accuracy: 0.5608
  date: 2020-10-27_14-55-31
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 6
  loss: 1.2388158322811127
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 130.91883897781372
  time_this_iter_s: 19.248765230178833
  time_total_s: 130.91883897781372
  timestamp: 1603810531
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 5.8/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: None | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.081887158033252
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.49804 |     0.4545 |                    1 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.4912  |     0.4491 |                    1 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.63233 |     0.3997 |                    1 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.23882 |     0.5608 |                    6 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2319)[0m [2,  6000] loss: 0.491
[2m[36m(pid=2331)[0m [2,  6000] loss: 0.492
[2m[36m(pid=2299)[0m [2,  6000] loss: 0.485
[2m[36m(pid=2319)[0m [2,  8000] loss: 0.372
[2m[36m(pid=2331)[0m [2,  8000] loss: 0.369
[2m[36m(pid=2299)[0m [2,  8000] loss: 0.367
[2m[36m(pid=2304)[0m [7,  2000] loss: 1.207
[2m[36m(pid=2319)[0m [2, 10000] loss: 0.299
[2m[36m(pid=2331)[0m [2, 10000] loss: 0.283
Result for DEFAULT_2714c_00006:
  accuracy: 0.5327
  date: 2020-10-27_14-55-50
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 7
  loss: 1.3224704763412476
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 150.1171042919159
  time_this_iter_s: 19.198265314102173
  time_total_s: 150.1171042919159
  timestamp: 1603810550
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 5.8/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: None | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.081887158033252
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.49804 |     0.4545 |                    1 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.4912  |     0.4491 |                    1 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.63233 |     0.3997 |                    1 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.32247 |     0.5327 |                    7 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [2, 10000] loss: 0.278
[2m[36m(pid=2319)[0m [2, 12000] loss: 0.244
[2m[36m(pid=2331)[0m [2, 12000] loss: 0.240
[2m[36m(pid=2299)[0m [2, 12000] loss: 0.239
[2m[36m(pid=2319)[0m [2, 14000] loss: 0.211
[2m[36m(pid=2304)[0m [8,  2000] loss: 1.192
[2m[36m(pid=2331)[0m [2, 14000] loss: 0.202
[2m[36m(pid=2299)[0m [2, 14000] loss: 0.198
Result for DEFAULT_2714c_00006:
  accuracy: 0.5572
  date: 2020-10-27_14-56-09
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 8
  loss: 1.2403597810268403
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 169.12370991706848
  time_this_iter_s: 19.006605625152588
  time_total_s: 169.12370991706848
  timestamp: 1603810569
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 5.8/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.081887158033252
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.49804 |     0.4545 |                    1 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.4912  |     0.4491 |                    1 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.63233 |     0.3997 |                    1 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.24036 |     0.5572 |                    8 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2319)[0m [2, 16000] loss: 0.182
[2m[36m(pid=2331)[0m [2, 16000] loss: 0.180
[2m[36m(pid=2299)[0m [2, 16000] loss: 0.172
[2m[36m(pid=2319)[0m [2, 18000] loss: 0.162
[2m[36m(pid=2331)[0m [2, 18000] loss: 0.155
[2m[36m(pid=2299)[0m [2, 18000] loss: 0.153
[2m[36m(pid=2304)[0m [9,  2000] loss: 1.182
[2m[36m(pid=2319)[0m [2, 20000] loss: 0.146
[2m[36m(pid=2331)[0m [2, 20000] loss: 0.140
Result for DEFAULT_2714c_00006:
  accuracy: 0.5702
  date: 2020-10-27_14-56-28
  done: false
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 9
  loss: 1.227432115507126
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 188.06252789497375
  time_this_iter_s: 18.938817977905273
  time_total_s: 188.06252789497375
  timestamp: 1603810588
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 5.8/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.819041507768631 | Iter 1.000: -2.081887158033252
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.49804 |     0.4545 |                    1 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.4912  |     0.4491 |                    1 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.63233 |     0.3997 |                    1 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.22743 |     0.5702 |                    9 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [2, 20000] loss: 0.137
Result for DEFAULT_2714c_00003:
  accuracy: 0.464
  date: 2020-10-27_14-56-38
  done: false
  experiment_id: 4641904849b44d0d947c2224ac967bb0
  experiment_tag: 3_batch_size=2,l1=32,l2=8,lr=0.0011771
  hostname: efccb162df23
  iterations_since_restore: 2
  loss: 1.5139318237060682
  node_ip: 172.17.0.2
  pid: 2319
  should_checkpoint: true
  time_since_restore: 197.5998511314392
  time_this_iter_s: 88.61425638198853
  time_total_s: 197.5998511314392
  timestamp: 1603810598
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 2714c_00003

== Status ==
Memory usage on this node: 5.8/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.5139318237060682 | Iter 1.000: -2.081887158033252
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.49804 |     0.4545 |                    1 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.4912  |     0.4491 |                    1 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.51393 |     0.464  |                    2 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.22743 |     0.5702 |                    9 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_2714c_00001:
  accuracy: 0.4862
  date: 2020-10-27_14-56-39
  done: false
  experiment_id: de0c51a9658d467db512b0e041c9fc29
  experiment_tag: 1_batch_size=2,l1=16,l2=256,lr=0.0010197
  hostname: efccb162df23
  iterations_since_restore: 2
  loss: 1.4540383652240039
  node_ip: 172.17.0.2
  pid: 2331
  should_checkpoint: true
  time_since_restore: 198.37821292877197
  time_this_iter_s: 89.20569682121277
  time_total_s: 198.37821292877197
  timestamp: 1603810599
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 2714c_00001

Result for DEFAULT_2714c_00000:
  accuracy: 0.5015
  date: 2020-10-27_14-56-41
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 2
  loss: 1.3821836505576968
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 200.58847832679749
  time_this_iter_s: 89.73750376701355
  time_total_s: 200.58847832679749
  timestamp: 1603810601
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 2714c_00000

[2m[36m(pid=2304)[0m [10,  2000] loss: 1.175
[2m[36m(pid=2319)[0m [3,  2000] loss: 1.407
[2m[36m(pid=2331)[0m [3,  2000] loss: 1.367
Result for DEFAULT_2714c_00006:
  accuracy: 0.5712
  date: 2020-10-27_14-56-47
  done: true
  experiment_id: 3b17963a059b407aa6550a80693c57c6
  experiment_tag: 6_batch_size=16,l1=8,l2=32,lr=0.0033809
  hostname: efccb162df23
  iterations_since_restore: 10
  loss: 1.2217427539825438
  node_ip: 172.17.0.2
  pid: 2304
  should_checkpoint: true
  time_since_restore: 207.11082363128662
  time_this_iter_s: 19.048295736312866
  time_total_s: 207.11082363128662
  timestamp: 1603810607
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 2714c_00006

== Status ==
Memory usage on this node: 5.8/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 8/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (4 RUNNING, 6 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.38218 |     0.5015 |                    2 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.45404 |     0.4862 |                    2 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.51393 |     0.464  |                    2 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | RUNNING    | 172.17.0.2:2304 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [3,  2000] loss: 1.306
[2m[36m(pid=2319)[0m [3,  4000] loss: 0.704
[2m[36m(pid=2331)[0m [3,  4000] loss: 0.682
[2m[36m(pid=2299)[0m [3,  4000] loss: 0.661
[2m[36m(pid=2319)[0m [3,  6000] loss: 0.478
[2m[36m(pid=2331)[0m [3,  6000] loss: 0.467
[2m[36m(pid=2299)[0m [3,  6000] loss: 0.435
[2m[36m(pid=2319)[0m [3,  8000] loss: 0.349
[2m[36m(pid=2331)[0m [3,  8000] loss: 0.351
[2m[36m(pid=2299)[0m [3,  8000] loss: 0.328
[2m[36m(pid=2319)[0m [3, 10000] loss: 0.281
[2m[36m(pid=2331)[0m [3, 10000] loss: 0.275
[2m[36m(pid=2299)[0m [3, 10000] loss: 0.259
[2m[36m(pid=2319)[0m [3, 12000] loss: 0.237
[2m[36m(pid=2331)[0m [3, 12000] loss: 0.228
[2m[36m(pid=2299)[0m [3, 12000] loss: 0.212
[2m[36m(pid=2319)[0m [3, 14000] loss: 0.204
[2m[36m(pid=2331)[0m [3, 14000] loss: 0.197
[2m[36m(pid=2299)[0m [3, 14000] loss: 0.185
[2m[36m(pid=2319)[0m [3, 16000] loss: 0.174
[2m[36m(pid=2331)[0m [3, 16000] loss: 0.171
[2m[36m(pid=2299)[0m [3, 16000] loss: 0.156
[2m[36m(pid=2319)[0m [3, 18000] loss: 0.153
[2m[36m(pid=2331)[0m [3, 18000] loss: 0.150
[2m[36m(pid=2299)[0m [3, 18000] loss: 0.141
[2m[36m(pid=2319)[0m [3, 20000] loss: 0.135
[2m[36m(pid=2331)[0m [3, 20000] loss: 0.134
[2m[36m(pid=2299)[0m [3, 20000] loss: 0.127
Result for DEFAULT_2714c_00003:
  accuracy: 0.5014
  date: 2020-10-27_14-58-04
  done: false
  experiment_id: 4641904849b44d0d947c2224ac967bb0
  experiment_tag: 3_batch_size=2,l1=32,l2=8,lr=0.0011771
  hostname: efccb162df23
  iterations_since_restore: 3
  loss: 1.431871204275079
  node_ip: 172.17.0.2
  pid: 2319
  should_checkpoint: true
  time_since_restore: 283.5669946670532
  time_this_iter_s: 85.96714353561401
  time_total_s: 283.5669946670532
  timestamp: 1603810684
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 2714c_00003

== Status ==
Memory usage on this node: 5.2/240.1 GiB
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3235916884422303 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.38218 |     0.5015 |                    2 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.45404 |     0.4862 |                    2 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.43187 |     0.5014 |                    3 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_2714c_00001:
  accuracy: 0.5122
  date: 2020-10-27_14-58-05
  done: false
  experiment_id: de0c51a9658d467db512b0e041c9fc29
  experiment_tag: 1_batch_size=2,l1=16,l2=256,lr=0.0010197
  hostname: efccb162df23
  iterations_since_restore: 3
  loss: 1.3696371508978307
  node_ip: 172.17.0.2
  pid: 2331
  should_checkpoint: true
  time_since_restore: 284.62486720085144
  time_this_iter_s: 86.24665427207947
  time_total_s: 284.62486720085144
  timestamp: 1603810685
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 2714c_00001

Result for DEFAULT_2714c_00000:
  accuracy: 0.5594
  date: 2020-10-27_14-58-08
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 3
  loss: 1.2503072771973909
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 287.47713899612427
  time_this_iter_s: 86.88866066932678
  time_total_s: 287.47713899612427
  timestamp: 1603810688
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 2714c_00000

[2m[36m(pid=2319)[0m [4,  2000] loss: 1.351
[2m[36m(pid=2331)[0m [4,  2000] loss: 1.307
[2m[36m(pid=2299)[0m [4,  2000] loss: 1.230
[2m[36m(pid=2319)[0m [4,  4000] loss: 0.675
[2m[36m(pid=2331)[0m [4,  4000] loss: 0.654
[2m[36m(pid=2299)[0m [4,  4000] loss: 0.605
[2m[36m(pid=2319)[0m [4,  6000] loss: 0.453
[2m[36m(pid=2331)[0m [4,  6000] loss: 0.448
[2m[36m(pid=2299)[0m [4,  6000] loss: 0.409
[2m[36m(pid=2319)[0m [4,  8000] loss: 0.336
[2m[36m(pid=2331)[0m [4,  8000] loss: 0.329
[2m[36m(pid=2299)[0m [4,  8000] loss: 0.300
[2m[36m(pid=2319)[0m [4, 10000] loss: 0.269
[2m[36m(pid=2331)[0m [4, 10000] loss: 0.272
[2m[36m(pid=2299)[0m [4, 10000] loss: 0.242
[2m[36m(pid=2319)[0m [4, 12000] loss: 0.223
[2m[36m(pid=2331)[0m [4, 12000] loss: 0.214
[2m[36m(pid=2299)[0m [4, 12000] loss: 0.196
[2m[36m(pid=2319)[0m [4, 14000] loss: 0.192
[2m[36m(pid=2331)[0m [4, 14000] loss: 0.191
[2m[36m(pid=2299)[0m [4, 14000] loss: 0.176
[2m[36m(pid=2319)[0m [4, 16000] loss: 0.172
[2m[36m(pid=2331)[0m [4, 16000] loss: 0.168
[2m[36m(pid=2299)[0m [4, 16000] loss: 0.150
[2m[36m(pid=2319)[0m [4, 18000] loss: 0.155
[2m[36m(pid=2331)[0m [4, 18000] loss: 0.146
[2m[36m(pid=2299)[0m [4, 18000] loss: 0.133
[2m[36m(pid=2319)[0m [4, 20000] loss: 0.138
[2m[36m(pid=2331)[0m [4, 20000] loss: 0.135
[2m[36m(pid=2299)[0m [4, 20000] loss: 0.119
Result for DEFAULT_2714c_00003:
  accuracy: 0.5202
  date: 2020-10-27_14-59-40
  done: true
  experiment_id: 4641904849b44d0d947c2224ac967bb0
  experiment_tag: 3_batch_size=2,l1=32,l2=8,lr=0.0011771
  hostname: efccb162df23
  iterations_since_restore: 4
  loss: 1.3798616365525407
  node_ip: 172.17.0.2
  pid: 2319
  should_checkpoint: true
  time_since_restore: 380.00303292274475
  time_this_iter_s: 96.43603825569153
  time_total_s: 380.00303292274475
  timestamp: 1603810780
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 2714c_00003

== Status ==
Memory usage on this node: 5.0/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.25031 |     0.5594 |                    3 |
| DEFAULT_2714c_00001 | RUNNING    | 172.17.0.2:2331 |            2 |   16 |  256 | 0.00101973  | 1.36964 |     0.5122 |                    3 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | RUNNING    | 172.17.0.2:2319 |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_2714c_00001:
  accuracy: 0.5087
  date: 2020-10-27_14-59-42
  done: true
  experiment_id: de0c51a9658d467db512b0e041c9fc29
  experiment_tag: 1_batch_size=2,l1=16,l2=256,lr=0.0010197
  hostname: efccb162df23
  iterations_since_restore: 4
  loss: 1.3925921520148636
  node_ip: 172.17.0.2
  pid: 2331
  should_checkpoint: true
  time_since_restore: 381.66263580322266
  time_this_iter_s: 97.03776860237122
  time_total_s: 381.66263580322266
  timestamp: 1603810782
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 2714c_00001

Result for DEFAULT_2714c_00000:
  accuracy: 0.5656
  date: 2020-10-27_14-59-44
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 4
  loss: 1.2285032491518184
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 384.33594727516174
  time_this_iter_s: 96.85880827903748
  time_total_s: 384.33594727516174
  timestamp: 1603810784
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 2714c_00000

[2m[36m(pid=2299)[0m [5,  2000] loss: 1.121
[2m[36m(pid=2299)[0m [5,  4000] loss: 0.568
[2m[36m(pid=2299)[0m [5,  6000] loss: 0.392
[2m[36m(pid=2299)[0m [5,  8000] loss: 0.277
[2m[36m(pid=2299)[0m [5, 10000] loss: 0.236
[2m[36m(pid=2299)[0m [5, 12000] loss: 0.191
[2m[36m(pid=2299)[0m [5, 14000] loss: 0.163
[2m[36m(pid=2299)[0m [5, 16000] loss: 0.143
[2m[36m(pid=2299)[0m [5, 18000] loss: 0.129
[2m[36m(pid=2299)[0m [5, 20000] loss: 0.113
Result for DEFAULT_2714c_00000:
  accuracy: 0.6077
  date: 2020-10-27_15-01-09
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 5
  loss: 1.1318580518282018
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 468.49117136001587
  time_this_iter_s: 84.15522408485413
  time_total_s: 468.49117136001587
  timestamp: 1603810869
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 2714c_00000

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.13186 |     0.6077 |                    5 |
| DEFAULT_2714c_00001 | TERMINATED |                 |            2 |   16 |  256 | 0.00101973  | 1.39259 |     0.5087 |                    4 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [6,  2000] loss: 1.085
[2m[36m(pid=2299)[0m [6,  4000] loss: 0.545
[2m[36m(pid=2299)[0m [6,  6000] loss: 0.361
[2m[36m(pid=2299)[0m [6,  8000] loss: 0.271
[2m[36m(pid=2299)[0m [6, 10000] loss: 0.225
[2m[36m(pid=2299)[0m [6, 12000] loss: 0.182
[2m[36m(pid=2299)[0m [6, 14000] loss: 0.154
[2m[36m(pid=2299)[0m [6, 16000] loss: 0.140
[2m[36m(pid=2299)[0m [6, 18000] loss: 0.121
[2m[36m(pid=2299)[0m [6, 20000] loss: 0.111
Result for DEFAULT_2714c_00000:
  accuracy: 0.5956
  date: 2020-10-27_15-02-32
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 6
  loss: 1.1518056997684063
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 552.2604835033417
  time_this_iter_s: 83.7693121433258
  time_total_s: 552.2604835033417
  timestamp: 1603810952
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 2714c_00000

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.15181 |     0.5956 |                    6 |
| DEFAULT_2714c_00001 | TERMINATED |                 |            2 |   16 |  256 | 0.00101973  | 1.39259 |     0.5087 |                    4 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [7,  2000] loss: 1.051
[2m[36m(pid=2299)[0m [7,  4000] loss: 0.528
[2m[36m(pid=2299)[0m [7,  6000] loss: 0.347
[2m[36m(pid=2299)[0m [7,  8000] loss: 0.261
[2m[36m(pid=2299)[0m [7, 10000] loss: 0.217
[2m[36m(pid=2299)[0m [7, 12000] loss: 0.174
[2m[36m(pid=2299)[0m [7, 14000] loss: 0.152
[2m[36m(pid=2299)[0m [7, 16000] loss: 0.133
[2m[36m(pid=2299)[0m [7, 18000] loss: 0.115
[2m[36m(pid=2299)[0m [7, 20000] loss: 0.106
Result for DEFAULT_2714c_00000:
  accuracy: 0.598
  date: 2020-10-27_15-03-55
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 7
  loss: 1.1538957916538697
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 635.241415977478
  time_this_iter_s: 82.98093247413635
  time_total_s: 635.241415977478
  timestamp: 1603811035
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 2714c_00000

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.2403597810268403 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.1539  |     0.598  |                    7 |
| DEFAULT_2714c_00001 | TERMINATED |                 |            2 |   16 |  256 | 0.00101973  | 1.39259 |     0.5087 |                    4 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [8,  2000] loss: 1.008
[2m[36m(pid=2299)[0m [8,  4000] loss: 0.506
[2m[36m(pid=2299)[0m [8,  6000] loss: 0.333
[2m[36m(pid=2299)[0m [8,  8000] loss: 0.263
[2m[36m(pid=2299)[0m [8, 10000] loss: 0.204
[2m[36m(pid=2299)[0m [8, 12000] loss: 0.175
[2m[36m(pid=2299)[0m [8, 14000] loss: 0.150
[2m[36m(pid=2299)[0m [8, 16000] loss: 0.126
[2m[36m(pid=2299)[0m [8, 18000] loss: 0.112
[2m[36m(pid=2299)[0m [8, 20000] loss: 0.103
Result for DEFAULT_2714c_00000:
  accuracy: 0.6168
  date: 2020-10-27_15-05-20
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 8
  loss: 1.1026301981414552
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 719.536670923233
  time_this_iter_s: 84.295254945755
  time_total_s: 719.536670923233
  timestamp: 1603811120
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 2714c_00000

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.1714949895841478 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.10263 |     0.6168 |                    8 |
| DEFAULT_2714c_00001 | TERMINATED |                 |            2 |   16 |  256 | 0.00101973  | 1.39259 |     0.5087 |                    4 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [9,  2000] loss: 0.943
[2m[36m(pid=2299)[0m [9,  4000] loss: 0.481
[2m[36m(pid=2299)[0m [9,  6000] loss: 0.327
[2m[36m(pid=2299)[0m [9,  8000] loss: 0.257
[2m[36m(pid=2299)[0m [9, 10000] loss: 0.201
[2m[36m(pid=2299)[0m [9, 12000] loss: 0.167
[2m[36m(pid=2299)[0m [9, 14000] loss: 0.144
[2m[36m(pid=2299)[0m [9, 16000] loss: 0.129
[2m[36m(pid=2299)[0m [9, 18000] loss: 0.108
[2m[36m(pid=2299)[0m [9, 20000] loss: 0.102
Result for DEFAULT_2714c_00000:
  accuracy: 0.6059
  date: 2020-10-27_15-06-43
  done: false
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 9
  loss: 1.1295733039892308
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 803.3343524932861
  time_this_iter_s: 83.7976815700531
  time_total_s: 803.3343524932861
  timestamp: 1603811203
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 2714c_00000

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -1.1714949895841478 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.12957 |     0.6059 |                    9 |
| DEFAULT_2714c_00001 | TERMINATED |                 |            2 |   16 |  256 | 0.00101973  | 1.39259 |     0.5087 |                    4 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=2299)[0m [10,  2000] loss: 0.948
[2m[36m(pid=2299)[0m [10,  4000] loss: 0.471
[2m[36m(pid=2299)[0m [10,  6000] loss: 0.326
[2m[36m(pid=2299)[0m [10,  8000] loss: 0.242
[2m[36m(pid=2299)[0m [10, 10000] loss: 0.192
[2m[36m(pid=2299)[0m [10, 12000] loss: 0.162
[2m[36m(pid=2299)[0m [10, 14000] loss: 0.140
[2m[36m(pid=2299)[0m [10, 16000] loss: 0.124
[2m[36m(pid=2299)[0m [10, 18000] loss: 0.110
[2m[36m(pid=2299)[0m [10, 20000] loss: 0.099
Result for DEFAULT_2714c_00000:
  accuracy: 0.6194
  date: 2020-10-27_15-08-07
  done: true
  experiment_id: c981e3c338564cc2b2a72afbedeec142
  experiment_tag: 0_batch_size=2,l1=32,l2=128,lr=0.00034217
  hostname: efccb162df23
  iterations_since_restore: 10
  loss: 1.0973360311276512
  node_ip: 172.17.0.2
  pid: 2299
  should_checkpoint: true
  time_since_restore: 886.6628234386444
  time_this_iter_s: 83.32847094535828
  time_total_s: 886.6628234386444
  timestamp: 1603811287
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 2714c_00000

== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -1.1714949895841478 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (1 RUNNING, 9 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | RUNNING    | 172.17.0.2:2299 |            2 |   32 |  128 | 0.000342167 | 1.09734 |     0.6194 |                   10 |
| DEFAULT_2714c_00001 | TERMINATED |                 |            2 |   16 |  256 | 0.00101973  | 1.39259 |     0.5087 |                    4 |
| DEFAULT_2714c_00002 | TERMINATED |                 |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | TERMINATED |                 |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |                 |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |                 |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |                 |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |                 |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |                 |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |                 |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -1.1714949895841478 | Iter 4.000: -1.3517266624973856 | Iter 2.000: -1.4540383652240039 | Iter 1.000: -2.081887158033252
Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/157.67 GiB heap, 0.0/49.37 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (10 TERMINATED)
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_2714c_00000 | TERMINATED |       |            2 |   32 |  128 | 0.000342167 | 1.09734 |     0.6194 |                   10 |
| DEFAULT_2714c_00001 | TERMINATED |       |            2 |   16 |  256 | 0.00101973  | 1.39259 |     0.5087 |                    4 |
| DEFAULT_2714c_00002 | TERMINATED |       |           16 |    4 |    8 | 0.00010686  | 2.3089  |     0.0975 |                    1 |
| DEFAULT_2714c_00003 | TERMINATED |       |            2 |   32 |    8 | 0.00117706  | 1.37986 |     0.5202 |                    4 |
| DEFAULT_2714c_00004 | TERMINATED |       |            2 |   32 |    8 | 0.0592514   | 2.43297 |     0.0976 |                    1 |
| DEFAULT_2714c_00005 | TERMINATED |       |           16 |   64 |    8 | 0.000324236 | 2.30344 |     0.1124 |                    1 |
| DEFAULT_2714c_00006 | TERMINATED |       |           16 |    8 |   32 | 0.00338091  | 1.22174 |     0.5712 |                   10 |
| DEFAULT_2714c_00007 | TERMINATED |       |           16 |  256 |  128 | 0.0544753   | 2.22264 |     0.1509 |                    2 |
| DEFAULT_2714c_00008 | TERMINATED |       |            2 |   16 |   16 | 0.0594805   | 2.35479 |     0.0981 |                    1 |
| DEFAULT_2714c_00009 | TERMINATED |       |            2 |  256 |    8 | 0.00435915  | 2.17633 |     0.2342 |                    1 |
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


Best trial config: {'l1': 32, 'l2': 128, 'lr': 0.000342167442687017, 'batch_size': 2}
Best trial final validation loss: 1.0973360311276512
Best trial final validation accuracy: 0.6194
Files already downloaded and verified
Files already downloaded and verified
Best trial test set accuracy: 0.6126
</pre></div>
</div>
<p>If you run the code, an example output could look like this:</p>
<p>Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.</p>
<p>So that’s it! You can now tune the parameters of your PyTorch models.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 15 minutes  7.282 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/95074cd7ce8c3e57a92e7a9c49182e6a/hyperparameter_tuning_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">hyperparameter_tuning_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/c24b93738bc036c1b66d0387555bf69a/hyperparameter_tuning_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">hyperparameter_tuning_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="../advanced/dispatcher.html" rel="prev" title="Registering a Dispatched Operator in C++"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr class="helpful-hr hr-top"/>
<div class="helpful-container">
<div class="helpful-question">Was this helpful?</div>
<div class="helpful-question yes-link" data-behavior="was-this-helpful-event" data-response="yes">Yes</div>
<div class="helpful-question no-link" data-behavior="was-this-helpful-event" data-response="no">No</div>
<div class="was-helpful-thank-you">Thank you</div>
</div>
<hr class="helpful-hr hr-bottom"/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Hyperparameter tuning with Ray Tune</a><ul>
<li><a class="reference internal" href="#setup-imports">Setup / Imports</a></li>
<li><a class="reference internal" href="#data-loaders">Data loaders</a></li>
<li><a class="reference internal" href="#configurable-neural-network">Configurable neural network</a></li>
<li><a class="reference internal" href="#the-train-function">The train function</a><ul>
<li><a class="reference internal" href="#adding-multi-gpu-support-with-dataparallel">Adding (multi) GPU support with DataParallel</a></li>
<li><a class="reference internal" href="#communicating-with-ray-tune">Communicating with Ray Tune</a></li>
<li><a class="reference internal" href="#full-training-function">Full training function</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-set-accuracy">Test set accuracy</a></li>
<li><a class="reference internal" href="#configuring-the-search-space">Configuring the search space</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>
<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Download',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='was-this-helpful-event']").on('click', function(){
    $(".helpful-question").hide();
    $(".was-helpful-thank-you").show();
    fbq('trackCustom', "Was this Helpful?", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      helpful: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Was this Helpful?',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
    gtag('event', $(this).attr("data-response"), {
      'event_category': 'Was this Helpful?',
      'event_label': $("h1").first().text()
    });
   });

   if (location.pathname == "/") {
     $(".helpful-container").hide();
     $(".hr-bottom").hide();
   }
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1"/>
</noscript>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Stay Connected</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
<a class="youtube" href="https://www.youtube.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg">
</img></div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/features">Features</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/hub">PyTorch Hub</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>